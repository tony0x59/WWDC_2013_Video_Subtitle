

1
00:00:00.506 --> 00:00:10.706 A:middle
[ Silence ]

2
00:00:11.206 --> 00:00:11.886 A:middle
&gt;&gt; Good morning everyone.

3
00:00:12.496 --> 00:00:14.316 A:middle
My name is Tony Guetta
and I'm the Manager

4
00:00:14.316 --> 00:00:15.576 A:middle
in the Core Audio
group at Apple.

5
00:00:15.716 --> 00:00:17.186 A:middle
And today, I'm going
to talk to you about,

6
00:00:17.186 --> 00:00:21.356 A:middle
What's New in Core
Audio for iOS.

7
00:00:21.476 --> 00:00:23.706 A:middle
We're going to begin with a
very high level overview of some

8
00:00:23.756 --> 00:00:25.466 A:middle
of the new audio
features in iOS 7.

9
00:00:25.626 --> 00:00:28.106 A:middle
And for the majority of this
session, we're going to talk--

10
00:00:28.106 --> 00:00:30.556 A:middle
spend our time focused on one
new technology in particular

11
00:00:30.766 --> 00:00:32.305 A:middle
that we think you're going
to be very excited about.

12
00:00:32.625 --> 00:00:34.896 A:middle
So, let's dive in to the
list of new features.

13
00:00:35.906 --> 00:00:39.756 A:middle
First is Audio Input Selection
and with input selection,

14
00:00:39.886 --> 00:00:41.986 A:middle
your application now has
the ability to specify

15
00:00:41.986 --> 00:00:44.696 A:middle
which audio input it would like
to use in certain situations.

16
00:00:44.736 --> 00:00:48.506 A:middle
So for example, if the user had
a wired headset plugged into his

17
00:00:48.506 --> 00:00:50.706 A:middle
or her device, but your
app wanted to continue

18
00:00:50.706 --> 00:00:52.396 A:middle
to use the built-in
microphone for input,

19
00:00:52.636 --> 00:00:55.506 A:middle
you now have the
capability to control that.

20
00:00:56.166 --> 00:00:58.436 A:middle
With input selection, you can
also choose which microphone

21
00:00:58.436 --> 00:01:00.456 A:middle
that you'd like to use on
our multi-mic platforms

22
00:01:00.996 --> 00:01:03.426 A:middle
and on devices that support
it such as the iPhone 5.

23
00:01:03.846 --> 00:01:04.616 A:middle
You can take advantage

24
00:01:04.616 --> 00:01:06.136 A:middle
of microphone beam
forming processing

25
00:01:06.636 --> 00:01:08.846 A:middle
to set an effective
microphone directivity

26
00:01:08.976 --> 00:01:12.096 A:middle
by specifying a polar pattern
such as cardioid or subcardioid.

27
00:01:14.716 --> 00:01:17.176 A:middle
We've made some enhancements
to multichannel audio on iOS 7.

28
00:01:17.556 --> 00:01:19.536 A:middle
And through the use of
the AVAudioSession API,

29
00:01:20.236 --> 00:01:22.266 A:middle
you can now discover the
maximum number of input

30
00:01:22.266 --> 00:01:23.446 A:middle
and output channels
that are supported

31
00:01:23.446 --> 00:01:25.656 A:middle
by the current audio route
as well as being able

32
00:01:25.656 --> 00:01:29.096 A:middle
to specify your preferred number
of input and output channels.

33
00:01:29.096 --> 00:01:31.006 A:middle
For audio outputs
supported such as HDMI,

34
00:01:31.906 --> 00:01:33.786 A:middle
you can obtain audio
channel labels

35
00:01:33.786 --> 00:01:35.806 A:middle
which associate a
particular audio channel

36
00:01:36.126 --> 00:01:38.196 A:middle
with the description of a
physical speaker location

37
00:01:38.196 --> 00:01:41.486 A:middle
such as front left, front
right, center and so on.

38
00:01:43.236 --> 00:01:44.916 A:middle
We've added some
extensions to Open AL

39
00:01:44.916 --> 00:01:47.886 A:middle
to enhance the gaming audio
experience in iOS 7 starting

40
00:01:47.886 --> 00:01:51.036 A:middle
with the ability to specify a
spatialization rendering quality

41
00:01:51.086 --> 00:01:52.376 A:middle
on a per-sound source basis.

42
00:01:53.126 --> 00:01:54.046 A:middle
Now, you might use this

43
00:01:54.046 --> 00:01:56.196 A:middle
to specify a very high
quality rendering algorithm

44
00:01:56.196 --> 00:01:58.146 A:middle
for the important sound
sources in your game.

45
00:01:58.396 --> 00:02:00.066 A:middle
But a less CPU intensive
algorithm

46
00:02:00.066 --> 00:02:02.036 A:middle
for those less importance
sound sources in your game.

47
00:02:03.576 --> 00:02:04.816 A:middle
We've also made some
improvements

48
00:02:04.816 --> 00:02:06.996 A:middle
to our high quality
spatialization

49
00:02:06.996 --> 00:02:07.676 A:middle
rendering algorithm.

50
00:02:08.326 --> 00:02:10.366 A:middle
And also added the ability
to support rendering

51
00:02:10.366 --> 00:02:12.356 A:middle
to multichannel output
hardware when it's available.

52
00:02:13.326 --> 00:02:15.016 A:middle
Finally, we've added
an extension

53
00:02:15.016 --> 00:02:16.116 A:middle
to allow capturing the output

54
00:02:16.116 --> 00:02:18.166 A:middle
of the current Open AL
3D rendering context.

55
00:02:18.666 --> 00:02:22.666 A:middle
We've added time-pitch
capabilities to Audio Queue.

56
00:02:22.916 --> 00:02:25.496 A:middle
So your application can now
control the speed up and slow

57
00:02:25.496 --> 00:02:27.266 A:middle
down of Audio Queue
playback both in terms

58
00:02:27.266 --> 00:02:28.576 A:middle
of time and in frequency.

59
00:02:31.276 --> 00:02:34.176 A:middle
We've enhanced the security
around audio recording in iOS 7

60
00:02:34.546 --> 00:02:37.456 A:middle
and we now require explicit user
approval before your application

61
00:02:37.456 --> 00:02:38.336 A:middle
can do audio input.

62
00:02:38.966 --> 00:02:40.166 A:middle
Now, the reason for
doing this is

63
00:02:40.166 --> 00:02:42.146 A:middle
to prevent a malicious
application from being able

64
00:02:42.146 --> 00:02:43.876 A:middle
to record a user without
him or her knowing it.

65
00:02:45.046 --> 00:02:46.976 A:middle
The way that this works
is very similar to the way

66
00:02:46.976 --> 00:02:49.876 A:middle
that the location service's
permission mechanism works.

67
00:02:49.876 --> 00:02:50.976 A:middle
In that the user is presented

68
00:02:50.976 --> 00:02:53.206 A:middle
with a model dialog
requesting his or her permission

69
00:02:53.206 --> 00:02:54.096 A:middle
to use the audio input.

70
00:02:54.486 --> 00:02:58.006 A:middle
The decision is made on
per-application basis

71
00:02:58.076 --> 00:02:59.196 A:middle
and it is a one-time decision.

72
00:02:59.726 --> 00:03:01.976 A:middle
However, if you'd like to
go in and change your mind

73
00:03:01.976 --> 00:03:03.206 A:middle
at a later time,
you can always go

74
00:03:03.206 --> 00:03:04.816 A:middle
into the Settings
application to do that.

75
00:03:06.666 --> 00:03:08.776 A:middle
Until the user has given
your application permission

76
00:03:08.776 --> 00:03:11.186 A:middle
to use audio input, you
will get silence so you need

77
00:03:11.186 --> 00:03:12.276 A:middle
to be prepared to handle that.

78
00:03:12.276 --> 00:03:15.876 A:middle
Now, what actually triggers
the dialog from being presented

79
00:03:15.876 --> 00:03:17.976 A:middle
to the user is an attempt
by your application

80
00:03:17.976 --> 00:03:20.626 A:middle
to use an audio session
category that would enable input

81
00:03:20.626 --> 00:03:22.546 A:middle
such as the record
category or play and record.

82
00:03:23.596 --> 00:03:26.076 A:middle
However, if you'd
like to have control

83
00:03:26.076 --> 00:03:27.856 A:middle
over when the user is
presented with his dialog

84
00:03:28.016 --> 00:03:29.966 A:middle
so that it can happen
at a more opportune time

85
00:03:29.966 --> 00:03:32.256 A:middle
for your application,
we've added some API

86
00:03:32.446 --> 00:03:35.426 A:middle
and AVAudioSession for
you to be able to do that.

87
00:03:38.226 --> 00:03:39.976 A:middle
Finally, just a note on
the AudioSession API.

88
00:03:40.426 --> 00:03:42.766 A:middle
As we mentioned at last year's
conference, the C version

89
00:03:42.766 --> 00:03:45.316 A:middle
of the AudioSession API is
officially being deprecated

90
00:03:45.316 --> 00:03:46.086 A:middle
in iOS 7.

91
00:03:46.326 --> 00:03:48.386 A:middle
So, we hope that over the
course of the past year,

92
00:03:48.576 --> 00:03:50.416 A:middle
you've all had the opportunity
to move your applications

93
00:03:50.416 --> 00:03:52.286 A:middle
over to using the
AVAudioSession API.

94
00:03:55.696 --> 00:03:57.976 A:middle
So, here is a summary of the
features that we just discussed.

95
00:03:57.976 --> 00:04:00.116 A:middle
We're not going to spend anymore
time today going over any

96
00:04:00.116 --> 00:04:01.446 A:middle
of these topics in
any more detail.

97
00:04:01.616 --> 00:04:03.326 A:middle
So, if you have any
questions about these

98
00:04:03.416 --> 00:04:05.636 A:middle
or like a more detailed
overview of any of these items,

99
00:04:06.026 --> 00:04:08.036 A:middle
we encourage you to come by
our labs either later today

100
00:04:08.316 --> 00:04:10.106 A:middle
or tomorrow morning and
we'd be happy to discuss

101
00:04:10.106 --> 00:04:10.936 A:middle
with you in more detail.

102
00:04:11.666 --> 00:04:14.046 A:middle
I'd also encourage you to have
a look at the documentation

103
00:04:14.046 --> 00:04:16.046 A:middle
in the various header files
that I outlined in the course

104
00:04:16.046 --> 00:04:17.276 A:middle
of going through
each of these topics.

105
00:04:18.276 --> 00:04:21.526 A:middle
So for the remainder of this
session, we're going to focus

106
00:04:21.526 --> 00:04:23.546 A:middle
on one new technology in
particular that again,

107
00:04:23.856 --> 00:04:25.406 A:middle
we think you're going
to be very excited about

108
00:04:25.406 --> 00:04:28.046 A:middle
and that's Inter-App Audio.

109
00:04:28.516 --> 00:04:29.926 A:middle
So what is Inter-App Audio?

110
00:04:30.286 --> 00:04:32.856 A:middle
Well, as the name implies,

111
00:04:32.856 --> 00:04:34.996 A:middle
Inter-App Audio provides
the ability to stream audio

112
00:04:34.996 --> 00:04:36.406 A:middle
between applications
in real-time.

113
00:04:36.756 --> 00:04:39.326 A:middle
So, if you have a really cool
effects application and you want

114
00:04:39.326 --> 00:04:40.806 A:middle
to integrate that into
your DAW application,

115
00:04:40.906 --> 00:04:42.726 A:middle
you now have the
ability to do that.

116
00:04:43.266 --> 00:04:46.146 A:middle
We've built Inter-App Audio on
top of existing Core Audio APIs

117
00:04:46.146 --> 00:04:47.986 A:middle
so it should be very
easy for you to integrate

118
00:04:47.986 --> 00:04:49.776 A:middle
into your existing applications

119
00:04:49.776 --> 00:04:52.616 A:middle
and deploy quickly
to the app store.

120
00:04:52.616 --> 00:04:54.326 A:middle
Because it's built into
the operating system,

121
00:04:54.526 --> 00:04:56.776 A:middle
the solution is very efficient
with zero additional latency

122
00:04:57.296 --> 00:05:00.026 A:middle
and should provide for a stable
platform for the evolution

123
00:05:00.026 --> 00:05:00.796 A:middle
of the feature over time.

124
00:05:01.706 --> 00:05:03.476 A:middle
Now, before we get into any
of the technical details

125
00:05:03.476 --> 00:05:06.406 A:middle
of how Inter-App Audio works,
I'd like to invite up Alec

126
00:05:06.636 --> 00:05:09.106 A:middle
from the GarageBand
team to give you a demo.

127
00:05:09.181 --> 00:05:11.181 A:middle
[ Applause ]

128
00:05:11.256 --> 00:05:16.566 A:middle
&gt;&gt; Thanks Tony.

129
00:05:17.056 --> 00:05:17.476 A:middle
Am I up?

130
00:05:17.766 --> 00:05:17.986 A:middle
&gt;&gt; Yeah.

131
00:05:18.416 --> 00:05:22.996 A:middle
&gt;&gt; My name is Alec, I am a
product designer for GarageBand

132
00:05:22.996 --> 00:05:26.296 A:middle
and Logic and I'm going to
switch over here to my iPad.

133
00:05:27.106 --> 00:05:30.496 A:middle
So, what I want to do today
is give a quick demonstration

134
00:05:30.546 --> 00:05:33.876 A:middle
about how we have been working
with the development version,

135
00:05:33.876 --> 00:05:36.016 A:middle
kind of a sneak peek into
a development version

136
00:05:36.016 --> 00:05:38.976 A:middle
of GarageBand and how we're
doing some experiments

137
00:05:39.096 --> 00:05:40.096 A:middle
with Inter-App Audio.

138
00:05:40.936 --> 00:05:43.946 A:middle
So, what I have up here is
just a simple FourTrack song

139
00:05:43.946 --> 00:05:45.736 A:middle
in GarageBand, I'm going
to play a little bit

140
00:05:45.736 --> 00:05:47.396 A:middle
so you can get an idea
of what it sounds like.

141
00:05:47.396 --> 00:05:47.936 A:middle
[ Music ]

142
00:05:47.936 --> 00:05:56.386 A:middle
OK. So the first thing
I want to do is I want

143
00:05:56.386 --> 00:05:58.556 A:middle
to add a little keyboard
part to this.

144
00:05:59.056 --> 00:06:01.736 A:middle
But instead of using one
of the built-in instruments

145
00:06:01.736 --> 00:06:05.946 A:middle
in GarageBand, I want to use
an instrument, on the system

146
00:06:05.946 --> 00:06:07.216 A:middle
that is not part of GarageBand.

147
00:06:07.216 --> 00:06:08.806 A:middle
So to do that, I'm going to go

148
00:06:08.806 --> 00:06:10.666 A:middle
out to the GarageBand
instrument browser.

149
00:06:10.776 --> 00:06:13.356 A:middle
Now, what we see here are
the instruments that ship

150
00:06:13.356 --> 00:06:15.096 A:middle
with GarageBand,
part of GarageBand.

151
00:06:15.576 --> 00:06:17.976 A:middle
And then we have a new
icon here, Music Apps.

152
00:06:18.266 --> 00:06:22.536 A:middle
I'm going to tap on that and
we see the icons of other apps

153
00:06:22.536 --> 00:06:26.466 A:middle
on the system which
are audio apps.

154
00:06:26.516 --> 00:06:30.116 A:middle
So, I'm going to click on
sampler one here and we'll see

155
00:06:30.116 --> 00:06:32.556 A:middle
that the sampler launches
in the background.

156
00:06:33.126 --> 00:06:36.976 A:middle
Now here it with the UI in the
foreground and we can hear it.

157
00:06:37.936 --> 00:06:39.906 A:middle
Now, you see there's a
transport here and that's,

158
00:06:39.906 --> 00:06:42.626 A:middle
this transport is remotely
controlling the transport

159
00:06:42.626 --> 00:06:43.386 A:middle
of GarageBand.

160
00:06:43.556 --> 00:06:45.456 A:middle
So, when I press the record
button, what we're going

161
00:06:45.456 --> 00:06:48.716 A:middle
to hear is a count off from
GarageBand and then the track

162
00:06:48.716 --> 00:06:53.856 A:middle
that I just played and I'll
record over the top of it.

163
00:06:54.356 --> 00:07:01.376 A:middle
[ Music ]

164
00:07:01.876 --> 00:07:03.236 A:middle
Brilliant musical passage.

165
00:07:04.816 --> 00:07:07.996 A:middle
So now, if I-- if you look up at
this transport again you'll see

166
00:07:07.996 --> 00:07:09.736 A:middle
that there's a GarageBand icon.

167
00:07:10.366 --> 00:07:12.916 A:middle
When I tap on that
icon, I switch back

168
00:07:12.916 --> 00:07:16.756 A:middle
to the GarageBand application
and now, in the tracks view,

169
00:07:17.126 --> 00:07:20.456 A:middle
a new track has been added
with this little keyboard part

170
00:07:20.456 --> 00:07:26.846 A:middle
that I played we
can listen to it.

171
00:07:26.936 --> 00:07:30.346 A:middle
[Background Music] And
add some keyboard to it.

172
00:07:30.346 --> 00:07:30.896 A:middle
[ Music ]

173
00:07:30.896 --> 00:07:33.746 A:middle
So, that was bringing audio
from another application,

174
00:07:33.746 --> 00:07:35.986 A:middle
controlling that
application in its interface,

175
00:07:35.986 --> 00:07:37.486 A:middle
and recording that
in GarageBand.

176
00:07:38.096 --> 00:07:39.626 A:middle
The next thing I
want to do is I want

177
00:07:39.626 --> 00:07:43.066 A:middle
to process an input
from GarageBand.

178
00:07:43.066 --> 00:07:47.736 A:middle
So, I'm going to put on my
little guitar here and we'll go

179
00:07:47.736 --> 00:07:50.896 A:middle
to the guitar amp in GarageBand.

180
00:07:51.426 --> 00:07:53.516 A:middle
Now, this guitar
amp is part of--

181
00:07:53.516 --> 00:07:57.466 A:middle
one of the instruments built
in the GarageBand and I'm going

182
00:07:57.466 --> 00:07:59.856 A:middle
to turn on input monitoring
so I can hear myself.

183
00:08:00.616 --> 00:08:04.886 A:middle
[Background Music] You
guys got it out there?

184
00:08:07.456 --> 00:08:10.076 A:middle
It's a little phase switch.

185
00:08:13.456 --> 00:08:15.586 A:middle
OK. Or we're going to--

186
00:08:15.586 --> 00:08:18.176 A:middle
there you go, that's
more rock and roll.

187
00:08:18.686 --> 00:08:21.186 A:middle
OK. So, that's a
good sound right?

188
00:08:21.186 --> 00:08:23.316 A:middle
That's using the guitar
app from GarageBand.

189
00:08:23.316 --> 00:08:25.456 A:middle
What I want to do though
is I want to process it

190
00:08:25.626 --> 00:08:27.476 A:middle
with another effect
on my system.

191
00:08:27.926 --> 00:08:31.426 A:middle
So again, I'm going to go into
the input settings in GarageBand

192
00:08:31.426 --> 00:08:32.416 A:middle
and if you see about halfway

193
00:08:32.416 --> 00:08:34.466 A:middle
down this list, it
says Effect App.

194
00:08:34.466 --> 00:08:38.076 A:middle
I'm going to tap on that and
we can see a list of apps

195
00:08:38.076 --> 00:08:40.525 A:middle
on my system that are
effects so I'm going

196
00:08:40.525 --> 00:08:42.046 A:middle
to click on this Audio Delay.

197
00:08:42.905 --> 00:08:45.606 A:middle
[Music] So, there is the delay

198
00:08:45.656 --> 00:08:47.366 A:middle
but it's not really
the settings I want.

199
00:08:47.496 --> 00:08:51.276 A:middle
So, I'm going to tap on
the Effect icon and switch

200
00:08:51.276 --> 00:08:52.546 A:middle
to the Effects Interface.

201
00:08:53.086 --> 00:08:54.636 A:middle
I'm going to take the feedback

202
00:08:54.636 --> 00:08:58.356 A:middle
down here a little
bit and the mix.

203
00:08:59.016 --> 00:08:59.196 A:middle
[Music] OK.

204
00:09:00.266 --> 00:09:04.836 A:middle
So that's a little bit better.

205
00:09:04.836 --> 00:09:06.726 A:middle
So now, what I'm doing
is I'm taking the input

206
00:09:07.296 --> 00:09:09.316 A:middle
through GarageBand, sending
it out to this effect

207
00:09:09.686 --> 00:09:11.476 A:middle
and bringing it back
on to GarageBand.

208
00:09:12.226 --> 00:09:13.676 A:middle
Then I can hit record.

209
00:09:13.676 --> 00:09:14.256 A:middle
[ Music ]

210
00:09:14.256 --> 00:09:54.026 A:middle
Now, if we switch back
to the tracks view,

211
00:09:55.626 --> 00:09:57.406 A:middle
we can see that new
region has been recorded

212
00:09:57.406 --> 00:09:59.606 A:middle
in GarageBand and if I play.

213
00:10:00.106 --> 00:10:03.576 A:middle
[ Music ]

214
00:10:04.076 --> 00:10:08.566 A:middle
There is the source
with the delay added

215
00:10:08.676 --> 00:10:10.676 A:middle
to it recorded in
the GarageBand.

216
00:10:14.816 --> 00:10:17.626 A:middle
So that's just the
quick overview

217
00:10:17.626 --> 00:10:19.536 A:middle
of how we're doing some
experiments inside this

218
00:10:19.536 --> 00:10:21.096 A:middle
development version
of GarageBand

219
00:10:21.186 --> 00:10:24.056 A:middle
with the new Inter-App
Audio APIs.

220
00:10:24.056 --> 00:10:25.976 A:middle
And next, we're going
to bring up Doug

221
00:10:25.976 --> 00:10:27.996 A:middle
to give you a little more
detail about how some

222
00:10:28.136 --> 00:10:36.726 A:middle
of the stuff works
under the hood.

223
00:10:36.726 --> 00:10:36.793 A:middle
[ Applause ]

224
00:10:36.793 --> 00:10:39.286 A:middle
&gt;&gt; Thank you Alec.

225
00:10:39.286 --> 00:10:42.096 A:middle
Hi, my name is Doug Wyatt, I'm a
plumber in the Core Audio group.

226
00:10:42.686 --> 00:10:44.896 A:middle
I'd like to present to
you some of the details

227
00:10:44.896 --> 00:10:46.776 A:middle
of the Inter-App Audio APIs.

228
00:10:48.376 --> 00:10:52.956 A:middle
So, conceptually here, we
have two kinds of applications

229
00:10:52.956 --> 00:10:54.746 A:middle
which we call the
host application

230
00:10:55.146 --> 00:10:56.476 A:middle
and the node application.

231
00:10:57.296 --> 00:10:58.536 A:middle
The fundamental distinction

232
00:10:58.536 --> 00:11:01.556 A:middle
between these two
applications is that the host is

233
00:11:01.556 --> 00:11:04.066 A:middle
where we ultimately
want the audio coming

234
00:11:04.066 --> 00:11:06.296 A:middle
from the node application
to end up.

235
00:11:06.296 --> 00:11:09.766 A:middle
So, GarageBand in this
example was a host application.

236
00:11:09.766 --> 00:11:12.626 A:middle
It was receiving audio from
the sampler application

237
00:11:13.066 --> 00:11:15.256 A:middle
and from the delay
effect application.

238
00:11:15.816 --> 00:11:18.396 A:middle
So, given these two
kinds of applications,

239
00:11:18.916 --> 00:11:20.256 A:middle
we're going to look at APIs

240
00:11:20.256 --> 00:11:22.776 A:middle
for how node applications
can register themselves

241
00:11:22.776 --> 00:11:26.306 A:middle
with the system and how host
applications can discover those

242
00:11:26.306 --> 00:11:27.916 A:middle
registered node applications.

243
00:11:28.816 --> 00:11:32.206 A:middle
We'll look at how
host applications can

244
00:11:32.206 --> 00:11:35.766 A:middle
of initiate connections through
the system to node applications.

245
00:11:35.766 --> 00:11:38.476 A:middle
And once those connections
are established,

246
00:11:38.846 --> 00:11:41.476 A:middle
the two applications can stream
audio between each other.

247
00:11:41.846 --> 00:11:45.986 A:middle
But, again, primarily the
destination has to be the host

248
00:11:46.036 --> 00:11:47.826 A:middle
that could optionally
send the audio to the node

249
00:11:47.826 --> 00:11:49.886 A:middle
if the node is providing
an effect.

250
00:11:50.506 --> 00:11:54.266 A:middle
We'll look at how furthermore
host applications can send MIDI

251
00:11:54.266 --> 00:11:57.576 A:middle
events to node applications to
control their audio rendering.

252
00:11:58.106 --> 00:12:01.656 A:middle
So for example, with
that sampler application,

253
00:12:01.656 --> 00:12:04.106 A:middle
the host could have been
actually sending the MIDI nodes

254
00:12:04.556 --> 00:12:08.946 A:middle
to the sampler and receiving
the rendered audio back.

255
00:12:09.556 --> 00:12:11.766 A:middle
We'll look at some interfaces

256
00:12:11.766 --> 00:12:14.226 A:middle
where the host can
express information

257
00:12:14.226 --> 00:12:17.016 A:middle
about its transport
controls and transport state

258
00:12:17.016 --> 00:12:19.826 A:middle
and timeline position
to node applications.

259
00:12:20.036 --> 00:12:21.306 A:middle
And finally, we'll look

260
00:12:21.306 --> 00:12:23.866 A:middle
at how node applications
can remotely control

261
00:12:23.866 --> 00:12:24.976 A:middle
host applications.

262
00:12:24.976 --> 00:12:28.416 A:middle
So, let's look inside
host applications.

263
00:12:28.956 --> 00:12:31.636 A:middle
So, this is your
basic standalone music

264
00:12:31.636 --> 00:12:33.516 A:middle
or audio application on iOS.

265
00:12:34.106 --> 00:12:38.366 A:middle
We have AURemoteIO audio unit
and its function is to connect

266
00:12:38.466 --> 00:12:41.606 A:middle
to the audio input and
output system with zero--

267
00:12:41.606 --> 00:12:45.876 A:middle
well, very low latency using
pretty much the same mechanisms

268
00:12:45.876 --> 00:12:49.426 A:middle
as on the desktop but always
through the RemoteIO audio unit.

269
00:12:49.786 --> 00:12:53.506 A:middle
So, feeding the audio unit, we
have the host's audio engine

270
00:12:53.506 --> 00:12:55.696 A:middle
and that can be constructed
in a number of ways,

271
00:12:55.696 --> 00:12:57.316 A:middle
we'll show some examples later.

272
00:12:58.016 --> 00:13:00.196 A:middle
But for the-- the purposes
of Inter-App Audio,

273
00:13:01.176 --> 00:13:04.206 A:middle
the host engine connects
to a node application

274
00:13:04.786 --> 00:13:06.806 A:middle
by instantiating
a node audio unit.

275
00:13:07.216 --> 00:13:10.976 A:middle
This is another Apple supplied
audio unit that, in effect,

276
00:13:11.426 --> 00:13:14.546 A:middle
creates the bridge to the
remote node application

277
00:13:14.606 --> 00:13:16.546 A:middle
to communicate audio with it.

278
00:13:17.916 --> 00:13:21.256 A:middle
Now, on the node side, a
node application is also

279
00:13:21.686 --> 00:13:25.796 A:middle
by default a normal application
with an AURemoteIO that can play

280
00:13:25.796 --> 00:13:29.366 A:middle
and record as always and it's
got its own audio engine.

281
00:13:30.386 --> 00:13:33.086 A:middle
What's a little different here
is in the Inter-App scenario,

282
00:13:33.086 --> 00:13:36.976 A:middle
the node application has its
input and output redirected

283
00:13:36.976 --> 00:13:40.236 A:middle
from the mic and speaker
to the host application.

284
00:13:40.866 --> 00:13:44.646 A:middle
So, that's the node application.

285
00:13:45.636 --> 00:13:48.996 A:middle
So, you see then we're
implementing this API

286
00:13:48.996 --> 00:13:50.966 A:middle
as a series of extensions

287
00:13:50.966 --> 00:13:54.276 A:middle
to the existing
AudioUnit.framework APIs.

288
00:13:54.276 --> 00:13:57.496 A:middle
The host sees the node
application as an audio unit

289
00:13:57.496 --> 00:13:58.546 A:middle
that it communicates with

290
00:13:59.206 --> 00:14:04.536 A:middle
and the nodes AURemoteIO unit
gets redirected to the host

291
00:14:04.596 --> 00:14:06.226 A:middle
so the node's communication

292
00:14:06.226 --> 00:14:09.226 A:middle
to the host application
is through that IO unit.

293
00:14:11.696 --> 00:14:15.486 A:middle
So, to express the capabilities
of these node applications

294
00:14:15.486 --> 00:14:17.346 A:middle
and to distinguish them a bit

295
00:14:17.406 --> 00:14:20.246 A:middle
from the existing
audio unit types,

296
00:14:20.336 --> 00:14:22.126 A:middle
we have these four new types.

297
00:14:23.306 --> 00:14:26.196 A:middle
They all are the same in that
they produce audio output

298
00:14:27.046 --> 00:14:30.136 A:middle
but they differ in what input
they receive from the host.

299
00:14:30.546 --> 00:14:33.116 A:middle
We have remote generators
which require no input.

300
00:14:33.796 --> 00:14:36.456 A:middle
We have remote instruments
which take MIDI input

301
00:14:36.456 --> 00:14:38.436 A:middle
to produce output, audio output.

302
00:14:39.156 --> 00:14:41.306 A:middle
We have effects which
are audio in and out.

303
00:14:41.776 --> 00:14:45.086 A:middle
And finally, we have music
effects which take both audio

304
00:14:45.086 --> 00:14:47.546 A:middle
and MIDI input and
produce audio.

305
00:14:48.876 --> 00:14:52.546 A:middle
So, node applications
use these component types

306
00:14:52.546 --> 00:14:54.286 A:middle
to describe their capabilities.

307
00:14:54.726 --> 00:14:57.776 A:middle
And furthermore one node
application may actually have

308
00:14:58.316 --> 00:15:01.966 A:middle
multiple sets of capabilities
and may wish to present itself

309
00:15:02.096 --> 00:15:03.996 A:middle
in multiple ways to hosts.

310
00:15:04.156 --> 00:15:05.486 A:middle
As a simple example,

311
00:15:05.486 --> 00:15:09.106 A:middle
a node application may produce
audio just fine on its own,

312
00:15:09.576 --> 00:15:10.876 A:middle
in which case, it's a generator.

313
00:15:11.316 --> 00:15:15.006 A:middle
It may optionally be
able to respond to MIDI

314
00:15:15.006 --> 00:15:16.936 A:middle
in producing that audio.

315
00:15:17.616 --> 00:15:19.566 A:middle
So, it can also be a generator.

316
00:15:19.566 --> 00:15:22.436 A:middle
So, such a node application
could publish itself

317
00:15:22.436 --> 00:15:24.326 A:middle
as two different
audio components

318
00:15:24.566 --> 00:15:25.996 A:middle
with separate capabilities.

319
00:15:26.856 --> 00:15:29.036 A:middle
Another example of
that is an application

320
00:15:29.036 --> 00:15:33.336 A:middle
like a guitar amp simulator
where the application appears

321
00:15:33.336 --> 00:15:36.816 A:middle
to the user as an effect
because audio is going in,

322
00:15:37.136 --> 00:15:39.636 A:middle
it's being processed in some
way and then it comes out.

323
00:15:40.206 --> 00:15:41.746 A:middle
But from the host's
point of view,

324
00:15:42.156 --> 00:15:45.616 A:middle
this application can appear
either as a generator an effect

325
00:15:45.776 --> 00:15:48.056 A:middle
and the node can publish
itself either way.

326
00:15:48.566 --> 00:15:52.676 A:middle
For example, if a node says I'm
a generator, it can continue

327
00:15:52.676 --> 00:15:57.906 A:middle
to receive microphone or a line
input from a guitar directly

328
00:15:57.976 --> 00:16:02.736 A:middle
from the underlying AURemoteIO
while only sending the audio

329
00:16:02.736 --> 00:16:03.736 A:middle
output to the host.

330
00:16:04.066 --> 00:16:05.446 A:middle
So again, that's generator mode.

331
00:16:05.986 --> 00:16:07.906 A:middle
Or if a host application

332
00:16:07.906 --> 00:16:10.686 A:middle
like GarageBand might have
a prerecorded guitar track

333
00:16:11.176 --> 00:16:13.846 A:middle
and want to process that through
the guitar amp simulator.

334
00:16:14.306 --> 00:16:17.226 A:middle
The guitar amp simulator can
function fully as an effect,

335
00:16:17.786 --> 00:16:20.036 A:middle
not communicate with the
audio hardware at all,

336
00:16:20.556 --> 00:16:22.896 A:middle
and just communicate
the two audio streams

337
00:16:23.276 --> 00:16:27.366 A:middle
between itself and the host.

338
00:16:27.966 --> 00:16:30.416 A:middle
Let's move on and look at
some of the requirements

339
00:16:30.416 --> 00:16:33.276 A:middle
for the Inter-App Audio
feature, it's available

340
00:16:33.276 --> 00:16:35.826 A:middle
on most iOS 7 compatible
devices,

341
00:16:35.866 --> 00:16:37.886 A:middle
the exception being
the iPhone 4.

342
00:16:38.196 --> 00:16:41.476 A:middle
And on the iPhone 4, you
don't really have to deal

343
00:16:41.476 --> 00:16:43.786 A:middle
with this specially because
what will happen is node

344
00:16:43.786 --> 00:16:46.916 A:middle
applications, if they
attempt to register themselves

345
00:16:46.916 --> 00:16:50.276 A:middle
with the system, those calls
will just fail silently,

346
00:16:50.276 --> 00:16:51.396 A:middle
the system will ignore them.

347
00:16:51.396 --> 00:16:55.776 A:middle
And on the host side, the
host will simply see no node

348
00:16:55.776 --> 00:16:58.626 A:middle
applications on the system.

349
00:16:58.626 --> 00:17:00.676 A:middle
Both host and node
applications need

350
00:17:00.676 --> 00:17:04.185 A:middle
to have a new entitlement called
"inter-app-audio" and this--

351
00:17:04.656 --> 00:17:06.566 A:middle
you can set this
for your application

352
00:17:06.566 --> 00:17:08.396 A:middle
in the Xcode Capabilities tab.

353
00:17:10.156 --> 00:17:15.296 A:middle
Furthermore, most applications
will want to have audio

354
00:17:15.296 --> 00:17:17.076 A:middle
in their UIBackgroundModes.

355
00:17:17.806 --> 00:17:21.036 A:middle
Most especially hosts
for obvious reasons

356
00:17:21.086 --> 00:17:23.925 A:middle
because hosts will keep
running their engines

357
00:17:23.925 --> 00:17:25.226 A:middle
when nodes are on
the foreground.

358
00:17:25.736 --> 00:17:29.436 A:middle
Also, nodes like the guitar amp
simulator I just mentioned may

359
00:17:29.436 --> 00:17:32.206 A:middle
want to continue accessing the
mic and to be able to do that,

360
00:17:32.256 --> 00:17:34.786 A:middle
they too need to have the
audio background mode.

361
00:17:35.766 --> 00:17:37.686 A:middle
One final requirement for nodes

362
00:17:37.686 --> 00:17:39.846 A:middle
in particular is
the MixWithOthers

363
00:17:39.846 --> 00:17:41.616 A:middle
AudioSessionCategoryOption.

364
00:17:42.276 --> 00:17:45.556 A:middle
Hosts can go either
way on this one.

365
00:17:45.666 --> 00:17:47.576 A:middle
We'll get into that
in more detail later.

366
00:17:48.176 --> 00:17:52.086 A:middle
OK. Getting in to the nuts
and bolts of the APIs here,

367
00:17:52.086 --> 00:17:54.276 A:middle
let's look at how node
applications can register

368
00:17:54.276 --> 00:17:57.876 A:middle
themselves with the system.

369
00:17:57.876 --> 00:18:01.656 A:middle
So, there's two pieces
of registering one's self

370
00:18:01.656 --> 00:18:02.766 A:middle
for a node application.

371
00:18:03.246 --> 00:18:07.186 A:middle
The first is an Info.plist
entry called AudioComponents.

372
00:18:07.626 --> 00:18:11.306 A:middle
So, the presence of this
Info.plist entry makes the app

373
00:18:11.586 --> 00:18:15.096 A:middle
discoverable and
launchable to the system.

374
00:18:15.396 --> 00:18:16.896 A:middle
The system knows,
oh I've got one

375
00:18:16.896 --> 00:18:18.706 A:middle
of this node applications
installed.

376
00:18:19.226 --> 00:18:22.866 A:middle
The second part of registration
is for the node application

377
00:18:22.866 --> 00:18:26.286 A:middle
to call AudioOutputUnitPublish
which checks

378
00:18:26.286 --> 00:18:30.106 A:middle
in that registration that it
advertised in its Info.plist.

379
00:18:30.286 --> 00:18:33.146 A:middle
It says, I've been launched and
here I am ready to communicate.

380
00:18:33.366 --> 00:18:36.316 A:middle
So let's look at those two
pieces in a little detail.

381
00:18:37.096 --> 00:18:41.286 A:middle
So here is the AudioComponents
entry in the Info.plist.

382
00:18:41.286 --> 00:18:43.756 A:middle
Its value is an array
and in that array,

383
00:18:43.756 --> 00:18:46.436 A:middle
there is a dictionary
for every AudioComponent

384
00:18:46.436 --> 00:18:47.836 A:middle
that the node wants to register.

385
00:18:48.576 --> 00:18:50.986 A:middle
And in that dictionary,
if you're familiar

386
00:18:50.986 --> 00:18:53.056 A:middle
with AudioComponentDescriptions
already,

387
00:18:53.056 --> 00:18:55.276 A:middle
you'll see some familiar
fields there.

388
00:18:55.276 --> 00:18:59.946 A:middle
There is the type, subtype and
manufacturer along with the name

389
00:18:59.946 --> 00:19:01.056 A:middle
and the version number.

390
00:19:01.656 --> 00:19:04.186 A:middle
So, that completely
describes the AudioComponent

391
00:19:04.566 --> 00:19:07.376 A:middle
that the node application
is advertising.

392
00:19:07.976 --> 00:19:13.026 A:middle
So, moving on to the second
part of the registration here,

393
00:19:13.636 --> 00:19:16.306 A:middle
this is when the node
application launches,

394
00:19:16.806 --> 00:19:21.676 A:middle
the first piece of code here
is the node's normal process

395
00:19:21.676 --> 00:19:24.416 A:middle
for creating its
AURemoteIO when it launches.

396
00:19:24.846 --> 00:19:26.856 A:middle
It creates an
AudioComponentDescription

397
00:19:26.856 --> 00:19:30.176 A:middle
describing the Apple
AURemoteIO instance,

398
00:19:30.176 --> 00:19:32.146 A:middle
it uses AudioComponentFindNext

399
00:19:32.146 --> 00:19:35.476 A:middle
to go find the AudioComponent
for the AURemoteIO.

400
00:19:35.996 --> 00:19:38.896 A:middle
And finally, it creates an
instance of the AURemoteIO

401
00:19:38.896 --> 00:19:43.326 A:middle
and this is something just about
every audio and music app on--

402
00:19:43.556 --> 00:19:47.586 A:middle
today will do for creating
a low latency IO channel.

403
00:19:48.106 --> 00:19:52.166 A:middle
What's new is that the node
application, to participate

404
00:19:52.166 --> 00:19:56.696 A:middle
in Inter-App Audio is now
going to connect that IO Unit

405
00:19:56.736 --> 00:20:00.086 A:middle
that it just created with
the component description

406
00:20:00.086 --> 00:20:02.356 A:middle
that was published in
the Info.plist entry.

407
00:20:02.976 --> 00:20:06.126 A:middle
So, to do that, we're
seeing this code here

408
00:20:06.126 --> 00:20:08.506 A:middle
that that node creates an
AudioComponentDescription

409
00:20:08.506 --> 00:20:11.736 A:middle
which matches the one in the
Info.plist we saw a moment ago.

410
00:20:12.356 --> 00:20:15.736 A:middle
It supplies the name and version
number and passes all that along

411
00:20:15.736 --> 00:20:17.456 A:middle
with the AURemoteIO instance

412
00:20:17.456 --> 00:20:20.806 A:middle
to a new API called
AudioOutputUnitPublish.

413
00:20:20.976 --> 00:20:24.476 A:middle
So again, that connects what
was advertised in the Info.plist

414
00:20:25.126 --> 00:20:29.476 A:middle
with the actual RemoteIO
instance in the application

415
00:20:29.806 --> 00:20:32.106 A:middle
to which the host
application will connect

416
00:20:32.106 --> 00:20:34.216 A:middle
as we'll see in a little bit.

417
00:20:34.216 --> 00:20:36.556 A:middle
So, to make this all
work, a requirement

418
00:20:36.556 --> 00:20:40.726 A:middle
of the node application is
to publish that RemoteIO unit

419
00:20:40.836 --> 00:20:44.426 A:middle
when it launches because the
node application is going

420
00:20:44.426 --> 00:20:46.986 A:middle
to get launched by host
applications when--

421
00:20:46.986 --> 00:20:48.896 A:middle
at times when the user
what's to use them.

422
00:20:49.936 --> 00:20:53.366 A:middle
And so, the node application
basically has to acknowledge,

423
00:20:53.366 --> 00:20:54.526 A:middle
I'm here, I've been launched.

424
00:20:55.666 --> 00:21:00.306 A:middle
And so, you can see then why the
Info.plist entry and the call

425
00:21:00.306 --> 00:21:04.636 A:middle
to AudioOutputUnitPublish
must have the same component

426
00:21:04.636 --> 00:21:06.426 A:middle
descriptions, names,
and versions.

427
00:21:07.426 --> 00:21:09.416 A:middle
One note here is
that by convention,

428
00:21:09.826 --> 00:21:13.106 A:middle
the component name should
contain your manufacture name

429
00:21:13.106 --> 00:21:17.236 A:middle
and application name and that
lets host applications sort the

430
00:21:17.236 --> 00:21:20.416 A:middle
available node applications by
manufacture name if they like.

431
00:21:20.416 --> 00:21:26.516 A:middle
So, that's the registration
process for node applications,

432
00:21:26.516 --> 00:21:29.416 A:middle
let's look at how host
applications can discover

433
00:21:29.416 --> 00:21:30.556 A:middle
those registrations.

434
00:21:33.836 --> 00:21:37.426 A:middle
So again, if you've used the
AudioComponent calls before,

435
00:21:37.626 --> 00:21:39.346 A:middle
this should look
fairly familiar.

436
00:21:39.726 --> 00:21:43.456 A:middle
What we here-- have here is a
loop where we want to iterate

437
00:21:43.526 --> 00:21:46.126 A:middle
through all of the components on
the system because we're looking

438
00:21:46.126 --> 00:21:48.656 A:middle
for nodes and there
are multiple types.

439
00:21:48.786 --> 00:21:50.286 A:middle
So, the simplest
way to do that is

440
00:21:50.286 --> 00:21:52.506 A:middle
to create a wild card
component description

441
00:21:52.506 --> 00:21:54.916 A:middle
and that's the searchDesc,
it's full of zeros.

442
00:21:55.586 --> 00:21:58.906 A:middle
And so then, this loop will
call AudioComponentFindNext

443
00:21:58.906 --> 00:22:02.936 A:middle
repeatedly and that
will yield in turn each

444
00:22:02.936 --> 00:22:05.166 A:middle
of the AudioComponents
on the system which are

445
00:22:05.526 --> 00:22:06.886 A:middle
in the local variable comp.

446
00:22:07.516 --> 00:22:10.486 A:middle
When we find null, then we've
gotten to the end of the list

447
00:22:10.486 --> 00:22:14.006 A:middle
of all the components in
the system and we're done

448
00:22:14.006 --> 00:22:15.286 A:middle
with our loop, we'll
have found them all.

449
00:22:16.126 --> 00:22:18.256 A:middle
Now, for each component on
the system, what we want

450
00:22:18.256 --> 00:22:20.716 A:middle
to do is call
AudioComponentGetDescription

451
00:22:21.596 --> 00:22:24.486 A:middle
and this will supply to us
the AudioComponent description

452
00:22:24.576 --> 00:22:27.446 A:middle
of the actual unit as
opposed to that wild card

453
00:22:27.646 --> 00:22:28.786 A:middle
that we used for searching.

454
00:22:29.436 --> 00:22:32.816 A:middle
So now, in foundDesc, we can
look at its component type

455
00:22:32.816 --> 00:22:37.706 A:middle
and see if it's one of the
four inter-app audio unit types

456
00:22:37.706 --> 00:22:40.466 A:middle
that we're interested in, the
RemoteEffects, RemoteGenerator,

457
00:22:40.466 --> 00:22:42.196 A:middle
RemoteInstrument, and
RemoteMusicEffect.

458
00:22:42.676 --> 00:22:46.596 A:middle
If we see one of those, then
we know we found the node.

459
00:22:47.136 --> 00:22:49.336 A:middle
OK. So the host has
found a node.

460
00:22:49.926 --> 00:22:52.496 A:middle
So now, I'm going to
walk through a little bit

461
00:22:52.496 --> 00:22:54.746 A:middle
of code here from one
of our sample apps.

462
00:22:55.296 --> 00:22:59.126 A:middle
It creates an objective C
object of its own just as a way

463
00:22:59.126 --> 00:23:01.486 A:middle
of storing information about
the nodes that it's found.

464
00:23:02.436 --> 00:23:05.686 A:middle
And it calls this class
RemoteAU and it stores away

465
00:23:05.686 --> 00:23:08.266 A:middle
into it the component
description that was found

466
00:23:08.806 --> 00:23:10.866 A:middle
and the AudioComponent
that was found.

467
00:23:11.886 --> 00:23:14.516 A:middle
It also fetches the
component's name and stores

468
00:23:14.516 --> 00:23:17.806 A:middle
that in the field of
the RemoteAU object.

469
00:23:18.696 --> 00:23:22.806 A:middle
It sets the image from
AudioComponentGetIcon

470
00:23:22.806 --> 00:23:25.536 A:middle
which is a new API call which
works with inter-app audio.

471
00:23:26.186 --> 00:23:28.046 A:middle
This gives you the
application of--

472
00:23:28.376 --> 00:23:30.966 A:middle
I'm sorry, the icon of
the node application.

473
00:23:32.836 --> 00:23:36.996 A:middle
We can also discover the time at
which the user last interacted

474
00:23:37.086 --> 00:23:41.656 A:middle
with the node app and this
can be useful if we want

475
00:23:41.696 --> 00:23:46.286 A:middle
to sort a list of available
node applications by time

476
00:23:46.286 --> 00:23:47.926 A:middle
of when they were
most recently used,

477
00:23:48.336 --> 00:23:50.016 A:middle
the way the home screen does.

478
00:23:50.686 --> 00:23:52.936 A:middle
So we've gathered up
all this information

479
00:23:52.936 --> 00:23:56.146 A:middle
about the node application,
and now we've built an array

480
00:23:56.146 --> 00:24:00.216 A:middle
from which we can drive a
table view and present the user

481
00:24:00.216 --> 00:24:05.306 A:middle
with a choice of node
applications to deal with.

482
00:24:06.046 --> 00:24:09.606 A:middle
One wrinkle though is having
cached all that information

483
00:24:09.606 --> 00:24:13.986 A:middle
in an array, it can become stale
and out of sync with the system.

484
00:24:14.436 --> 00:24:17.606 A:middle
Most notably, when apps
are installed and deleted

485
00:24:17.606 --> 00:24:21.656 A:middle
so if you find yourself caching
list of components like this,

486
00:24:21.656 --> 00:24:25.456 A:middle
you should probably also
listen to this new notification

487
00:24:25.456 --> 00:24:28.966 A:middle
that we supply, its name is
AudioComponentRegistrations

488
00:24:28.966 --> 00:24:30.196 A:middle
ChangedNotification.

489
00:24:30.586 --> 00:24:35.916 A:middle
So, you can pass that
to NSNotification center

490
00:24:35.916 --> 00:24:37.846 A:middle
to register for a notification.

491
00:24:38.136 --> 00:24:42.216 A:middle
In this example, we're supplying
a block to be called and then

492
00:24:42.216 --> 00:24:45.426 A:middle
that block which is called when
the notification or rather,

493
00:24:45.426 --> 00:24:48.166 A:middle
when the registration has
changed, we can refresh

494
00:24:48.236 --> 00:24:50.366 A:middle
that cached list of
audio units we built.

495
00:24:51.016 --> 00:24:55.346 A:middle
So, that's the process of
discovering node apps for host.

496
00:24:55.696 --> 00:24:57.656 A:middle
So now, we've built up a table

497
00:24:58.256 --> 00:25:01.656 A:middle
and maybe the user has
selected one of them

498
00:25:01.656 --> 00:25:03.246 A:middle
and in the host application now,

499
00:25:03.246 --> 00:25:05.116 A:middle
we want to actually
establish a connection

500
00:25:05.516 --> 00:25:08.836 A:middle
to the node application so
let's look at how that works.

501
00:25:09.886 --> 00:25:13.716 A:middle
The first step is very
simple because we held

502
00:25:13.716 --> 00:25:16.646 A:middle
on to the AudioComponent
of that node.

503
00:25:17.476 --> 00:25:20.356 A:middle
Now, all we have to do is create
an instance of that component

504
00:25:20.436 --> 00:25:22.266 A:middle
and now, we have an audio unit

505
00:25:22.386 --> 00:25:24.296 A:middle
through which we can
communicate with the node.

506
00:25:24.756 --> 00:25:27.746 A:middle
It's worth mentioning
that this is the moment

507
00:25:27.746 --> 00:25:30.556 A:middle
at which the node
application will get launched

508
00:25:30.556 --> 00:25:32.506 A:middle
into the background if it
it's not already running.

509
00:25:33.796 --> 00:25:36.006 A:middle
And we'll look it all the
mechanics of what happens

510
00:25:36.006 --> 00:25:37.486 A:middle
on the node side of that later.

511
00:25:37.826 --> 00:25:39.736 A:middle
Right now, we're just going
to focus on the host side.

512
00:25:40.446 --> 00:25:44.826 A:middle
So, the host has to do a fair--
a few steps here to get ready

513
00:25:44.906 --> 00:25:48.046 A:middle
to steam audio between
itself and the node.

514
00:25:49.396 --> 00:25:53.406 A:middle
Most importantly, the
host must be communicating

515
00:25:53.406 --> 00:25:57.376 A:middle
with the node using the same
hardware sample rate as--

516
00:25:57.466 --> 00:25:59.146 A:middle
or the same sample
rate as the hardware.

517
00:25:59.806 --> 00:26:04.036 A:middle
So, to be absolutely sure the
hardware sample rate is what

518
00:26:04.036 --> 00:26:07.156 A:middle
it's supposed to be, we should
be making our audio session

519
00:26:07.156 --> 00:26:08.666 A:middle
active if we haven't already.

520
00:26:09.996 --> 00:26:11.876 A:middle
So, once having done that,

521
00:26:11.876 --> 00:26:14.786 A:middle
then we can specify the audio
stream basic description

522
00:26:15.236 --> 00:26:19.516 A:middle
which is a detailed
description of the audio format

523
00:26:20.466 --> 00:26:23.116 A:middle
that the host wishes to use
to communicate with the node.

524
00:26:24.286 --> 00:26:26.936 A:middle
So, we can choose
mono or stereo.

525
00:26:26.936 --> 00:26:28.756 A:middle
In this example,
I've chosen stereo.

526
00:26:28.756 --> 00:26:32.136 A:middle
Here is where we're using
the hardware sample rate

527
00:26:32.756 --> 00:26:38.166 A:middle
And these lines of code here
are basically specifying 32 bit

528
00:26:38.166 --> 00:26:40.206 A:middle
floating-point, non-interleaved.

529
00:26:40.596 --> 00:26:43.866 A:middle
Now, the host application can
choose any format it likes here

530
00:26:44.006 --> 00:26:47.356 A:middle
and the system will perform
whatever conversions are

531
00:26:47.356 --> 00:26:50.926 A:middle
necessary as long as there's
not a sample rate conversion

532
00:26:51.086 --> 00:26:51.786 A:middle
being requested.

533
00:26:51.786 --> 00:26:56.196 A:middle
Again, you must use the sample
rate that matches the hardware.

534
00:26:57.426 --> 00:26:58.136 A:middle
All right.

535
00:26:58.136 --> 00:27:00.896 A:middle
Now, we have built up an
audio stream basic description

536
00:27:00.896 --> 00:27:02.906 A:middle
and we can use
AudioUnitSetProperty

537
00:27:02.906 --> 00:27:06.496 A:middle
on the node AudioUnit for
the stream format property

538
00:27:07.366 --> 00:27:10.476 A:middle
and this is specifying-- since
it's in the output scope,

539
00:27:10.476 --> 00:27:14.596 A:middle
this is specifying the output
format of the audio we need

540
00:27:14.596 --> 00:27:15.746 A:middle
to receive from the node.

541
00:27:15.866 --> 00:27:18.856 A:middle
If we're working with a
generator or instrument

542
00:27:18.856 --> 00:27:21.276 A:middle
which don't take audio
input, that's it, we've--

543
00:27:21.426 --> 00:27:25.786 A:middle
we're done, we've just
specified the output format.

544
00:27:26.146 --> 00:27:27.566 A:middle
But if we're dealing
with an effect,

545
00:27:27.686 --> 00:27:29.966 A:middle
then we should also
specify the input format.

546
00:27:30.426 --> 00:27:32.856 A:middle
And in many cases, it's
going to be identical

547
00:27:32.956 --> 00:27:35.396 A:middle
to the output format and so,

548
00:27:35.396 --> 00:27:39.486 A:middle
we can make that same call
using the input scope just

549
00:27:39.516 --> 00:27:42.936 A:middle
that the input format that we're
going to supply to the node.

550
00:27:44.076 --> 00:27:49.806 A:middle
So, having specified formats,
we can look how we're going

551
00:27:49.806 --> 00:27:52.426 A:middle
to get audio from the
host into the node

552
00:27:52.926 --> 00:27:56.496 A:middle
and this is starting it get into
the details of multiple ways

553
00:27:56.496 --> 00:27:58.776 A:middle
that your host may
be interacting

554
00:27:58.776 --> 00:27:59.866 A:middle
with the node AudioUnit.

555
00:28:00.216 --> 00:28:03.256 A:middle
Now, since we're connecting
input, this is only for effects

556
00:28:04.616 --> 00:28:08.426 A:middle
and the host at this point
can supply input to a node

557
00:28:08.426 --> 00:28:12.926 A:middle
from another audio unit using
AUGraphConnectNodeInput.

558
00:28:13.056 --> 00:28:15.836 A:middle
AUGraph is a higher level API
which I'm just going to touch

559
00:28:15.836 --> 00:28:20.586 A:middle
on a few times today but you can
use AUGraph to build up graphs

560
00:28:20.586 --> 00:28:23.236 A:middle
or a series of connections
between audio units.

561
00:28:24.316 --> 00:28:27.626 A:middle
The other way to make a
connection to the node's input

562
00:28:27.916 --> 00:28:30.096 A:middle
from some other audio unit is

563
00:28:30.096 --> 00:28:32.336 A:middle
with the AudioUnitProperty
MakeConnection.

564
00:28:33.606 --> 00:28:36.956 A:middle
Alternatively, a host can simply
supply a callback function

565
00:28:37.396 --> 00:28:39.236 A:middle
with the SetRenderCallback
property.

566
00:28:39.646 --> 00:28:42.066 A:middle
This callback function
gets called at render time

567
00:28:42.066 --> 00:28:46.016 A:middle
and the host supplies the audio
samples to be given to the node.

568
00:28:46.426 --> 00:28:49.036 A:middle
Now, as far as connecting
the output of the node,

569
00:28:49.116 --> 00:28:52.646 A:middle
this too depends on the way
you built your host engine.

570
00:28:53.196 --> 00:28:54.996 A:middle
If you're using audio
units, you want to connect

571
00:28:54.996 --> 00:28:57.366 A:middle
to the node output to
some other audio unit.

572
00:28:57.796 --> 00:29:00.416 A:middle
You can use the MakeConnection
property again.

573
00:29:01.146 --> 00:29:04.846 A:middle
If however you're pulling
audio into a custom engine,

574
00:29:04.846 --> 00:29:06.426 A:middle
then you would call
AudioUnitRender

575
00:29:06.996 --> 00:29:09.946 A:middle
but there's no setup
at this time for that.

576
00:29:11.276 --> 00:29:12.956 A:middle
We'll look at the
rendering process

577
00:29:12.956 --> 00:29:14.356 A:middle
in more detail a little later.

578
00:29:14.956 --> 00:29:22.006 A:middle
OK. One last a bit of mechanics
here that a host needs to do

579
00:29:22.006 --> 00:29:25.486 A:middle
to establish a reliable
connection to a node or actually

580
00:29:25.486 --> 00:29:29.706 A:middle
to reliably handle bad things
happening with the node is

581
00:29:30.166 --> 00:29:32.866 A:middle
to look out for what happens
when nodes become disconnected.

582
00:29:33.196 --> 00:29:35.996 A:middle
This could happen automatically
if the node app crashes,

583
00:29:36.326 --> 00:29:39.556 A:middle
if the system ejects it from
this memory before being

584
00:29:39.936 --> 00:29:41.726 A:middle
under memory pressure.

585
00:29:42.456 --> 00:29:44.196 A:middle
Also, if the host fails

586
00:29:44.196 --> 00:29:47.836 A:middle
to render the node
application regularly enough,

587
00:29:47.836 --> 00:29:49.526 A:middle
the system will evict it from--

588
00:29:49.866 --> 00:29:51.746 A:middle
or I'm sorry, will
break the connection.

589
00:29:52.206 --> 00:29:56.196 A:middle
When these things happen, then
the node AudioUnit becomes,

590
00:29:56.256 --> 00:29:59.466 A:middle
in effect of zombie,
meaning that it's--

591
00:29:59.596 --> 00:30:01.326 A:middle
there's still an
audio unit there.

592
00:30:01.426 --> 00:30:05.356 A:middle
You can make API calls on
it but they won't crash

593
00:30:06.256 --> 00:30:08.606 A:middle
but you will get errors
back and that's the error

594
00:30:08.606 --> 00:30:10.746 A:middle
that you'll get back, the
InstanceInvalidated error.

595
00:30:11.996 --> 00:30:16.136 A:middle
The mechanics of establishing
that disconnection callback -

596
00:30:16.456 --> 00:30:20.836 A:middle
we call
AudioUnitAddPropertyListener

597
00:30:20.956 --> 00:30:23.556 A:middle
for this new property
IsInterAppConnected.

598
00:30:24.696 --> 00:30:26.876 A:middle
Here is what you would do
in the connection listener,

599
00:30:26.876 --> 00:30:30.996 A:middle
you can fetch current value of
the property and see if it is 0

600
00:30:31.146 --> 00:30:35.446 A:middle
and if the local variable here
connected has become zero,

601
00:30:35.946 --> 00:30:38.136 A:middle
then you know the node
application has become

602
00:30:38.576 --> 00:30:40.646 A:middle
disconnected and you
should react accordingly.

603
00:30:41.716 --> 00:30:46.806 A:middle
So, all of that prep work
has led us up to the point

604
00:30:46.806 --> 00:30:49.066 A:middle
or we're ready to actually
initialize the node.

605
00:30:49.296 --> 00:30:53.736 A:middle
Now, the AudioUnit
initialize call basically says

606
00:30:53.736 --> 00:30:55.986 A:middle
to the system and
the other AudioUnit.

607
00:30:56.286 --> 00:30:57.436 A:middle
Here, allocate all

608
00:30:57.436 --> 00:30:59.406 A:middle
of the resources you
need for rendering.

609
00:30:59.986 --> 00:31:01.496 A:middle
In the case of inter-app audio,

610
00:31:01.886 --> 00:31:05.146 A:middle
the system at this point is
also allocating some resources

611
00:31:05.146 --> 00:31:07.626 A:middle
on behalf of that
connection such as the buffers

612
00:31:07.626 --> 00:31:10.706 A:middle
between the applications and
the real-time rendering thread

613
00:31:10.706 --> 00:31:11.966 A:middle
in the node application.

614
00:31:12.956 --> 00:31:14.656 A:middle
So, it's important to realize.

615
00:31:14.656 --> 00:31:18.756 A:middle
This is a point at which you are
beginning to consume resources

616
00:31:19.046 --> 00:31:21.526 A:middle
and as such, you have
the responsibility now

617
00:31:22.296 --> 00:31:24.706 A:middle
of calling AudioUnitRender
regularly

618
00:31:25.746 --> 00:31:27.846 A:middle
on this node audio unit.

619
00:31:29.296 --> 00:31:32.506 A:middle
So, that's the process
of setting up a host

620
00:31:32.506 --> 00:31:33.666 A:middle
to communicate with a node.

621
00:31:33.806 --> 00:31:36.896 A:middle
You activate your audio session,
you set your stream formats,

622
00:31:37.026 --> 00:31:39.966 A:middle
you connect your audio input,
add a disconnection listener,

623
00:31:40.026 --> 00:31:42.256 A:middle
and finally call
AudioUnitInitialize.

624
00:31:42.256 --> 00:31:46.666 A:middle
So having done that, you're at
the point now where you're ready

625
00:31:46.666 --> 00:31:50.116 A:middle
to begin streaming audio
between the two applications.

626
00:31:51.246 --> 00:31:54.466 A:middle
Let's look inside a host
application's engine

627
00:31:54.466 --> 00:31:55.206 A:middle
in more detail.

628
00:31:55.656 --> 00:31:59.036 A:middle
This is kind of a wonderfully
simple way to do things

629
00:31:59.036 --> 00:32:03.166 A:middle
if you can get your work
done using Apple AudioUnits.

630
00:32:03.166 --> 00:32:06.506 A:middle
So, the green box, the
green dotted lines--

631
00:32:07.256 --> 00:32:09.116 A:middle
box represents a host engine

632
00:32:09.116 --> 00:32:12.606 A:middle
but those red boxes inside are
all Apple supplied audio units.

633
00:32:12.876 --> 00:32:15.136 A:middle
So, there is the AURemoteIO,

634
00:32:15.136 --> 00:32:17.176 A:middle
we have a mixer AudioUnite
feeding that.

635
00:32:17.586 --> 00:32:20.356 A:middle
In feeding the mixer, we
have a file player AudioUnit

636
00:32:20.856 --> 00:32:22.836 A:middle
and the node AudioUnit.

637
00:32:23.736 --> 00:32:27.116 A:middle
But of course, there are many
things you would want to do

638
00:32:27.116 --> 00:32:29.586 A:middle
with audio that Apple doesn't
give you AudioUnits for.

639
00:32:29.586 --> 00:32:31.876 A:middle
If you want to that, then
you're going to write some code

640
00:32:31.876 --> 00:32:34.956 A:middle
of your own represented
by the green box

641
00:32:34.956 --> 00:32:36.556 A:middle
with the squiggly brackets.

642
00:32:36.946 --> 00:32:41.336 A:middle
So here, your engine is
feeding the AURemoteIO

643
00:32:41.536 --> 00:32:44.136 A:middle
and if you've written
an app like this before,

644
00:32:44.136 --> 00:32:47.386 A:middle
you know the way to provide
input to an AURemoteIO

645
00:32:47.386 --> 00:32:50.526 A:middle
from your own engine is with
the SetRenderCallback property.

646
00:32:51.266 --> 00:32:53.666 A:middle
And now in this case,
to fetch the audio

647
00:32:53.666 --> 00:32:57.316 A:middle
from the node AudioUnit, you
would call AudioUnitRender.

648
00:32:57.916 --> 00:33:03.126 A:middle
OK. So, that's a bunch
of stuff about how we--

649
00:33:03.286 --> 00:33:06.116 A:middle
a host application
interact with a node.

650
00:33:06.116 --> 00:33:09.676 A:middle
One final nice thing to
do for the user here is

651
00:33:09.676 --> 00:33:11.896 A:middle
to provide a way for the user

652
00:33:12.666 --> 00:33:15.806 A:middle
to bring the node
application to the foreground.

653
00:33:16.176 --> 00:33:22.296 A:middle
So, we can do this by asking
the audio unit for a PeerURL

654
00:33:22.296 --> 00:33:25.436 A:middle
and this URL is only
valid during the life

655
00:33:25.436 --> 00:33:26.276 A:middle
of the connection.

656
00:33:26.276 --> 00:33:28.166 A:middle
You don't want to hold on to it

657
00:33:28.166 --> 00:33:30.266 A:middle
because it's not going
to be useful later.

658
00:33:30.716 --> 00:33:33.576 A:middle
But right before the user
wants to switch in response

659
00:33:33.606 --> 00:33:35.016 A:middle
to that Icon tap or whatever,

660
00:33:35.556 --> 00:33:38.966 A:middle
you can fetch the PeerURL then
pass that to UIApplication

661
00:33:39.026 --> 00:33:43.196 A:middle
and ask it to open that URL and
that will accomplish the switch

662
00:33:43.446 --> 00:33:45.936 A:middle
of bringing the node
application to the foreground.

663
00:33:50.936 --> 00:33:54.446 A:middle
So, let's go back just
a little bit and look

664
00:33:54.516 --> 00:33:57.156 A:middle
at how node applications
see the process

665
00:33:57.156 --> 00:33:58.866 A:middle
of becoming connected to hosts.

666
00:34:01.556 --> 00:34:04.956 A:middle
So, the most important thing to
think about here as the author

667
00:34:04.956 --> 00:34:06.336 A:middle
of a node application is

668
00:34:06.416 --> 00:34:10.936 A:middle
that when the user opens
your application explicitly

669
00:34:10.936 --> 00:34:12.496 A:middle
from the home screen,
you're launched

670
00:34:12.496 --> 00:34:15.366 A:middle
into the foreground state,
you're ready start making music.

671
00:34:16.576 --> 00:34:19.306 A:middle
But if you're being
launched from the context

672
00:34:19.306 --> 00:34:22.545 A:middle
of a host application, you're
actually going to get launched

673
00:34:22.545 --> 00:34:25.045 A:middle
into the background state and
there are some limitations

674
00:34:25.045 --> 00:34:26.326 A:middle
about what you can do at this--

675
00:34:26.446 --> 00:34:28.436 A:middle
in this state and there's
also a requirement here.

676
00:34:29.096 --> 00:34:33.366 A:middle
You can't start running from the
background but you must create

677
00:34:33.366 --> 00:34:35.646 A:middle
and publish your I/O
unit as I showed earlier.

678
00:34:36.116 --> 00:34:40.126 A:middle
So, it's probably going
to be necessary and useful

679
00:34:40.456 --> 00:34:41.696 A:middle
in your node application

680
00:34:42.016 --> 00:34:44.906 A:middle
to ask UIApplication
what's the state here,

681
00:34:45.056 --> 00:34:47.196 A:middle
Am I in the background or
am I in the foreground?

682
00:34:47.496 --> 00:34:48.556 A:middle
and proceed accordingly.

683
00:34:50.976 --> 00:34:53.315 A:middle
So, node applications to find

684
00:34:53.315 --> 00:34:55.235 A:middle
out when they're
becoming connected

685
00:34:55.235 --> 00:34:57.966 A:middle
and disconnected can also listen

686
00:34:58.036 --> 00:35:01.166 A:middle
for the IsInterAppConnected
property just as I described

687
00:35:01.526 --> 00:35:03.086 A:middle
for host applications earlier.

688
00:35:04.596 --> 00:35:07.106 A:middle
For a node application,
you listen to this property

689
00:35:07.526 --> 00:35:10.036 A:middle
on your AURemoteIO instance.

690
00:35:11.456 --> 00:35:15.576 A:middle
So, in your property listener,
you can notice the transitions

691
00:35:15.576 --> 00:35:17.916 A:middle
of this property value
from zero to one.

692
00:35:18.236 --> 00:35:20.406 A:middle
When you see it becoming
true, then you know

693
00:35:20.406 --> 00:35:22.936 A:middle
that you're output unit has
been initialized underneath you

694
00:35:23.166 --> 00:35:26.076 A:middle
and that you should set
your audio session active

695
00:35:26.126 --> 00:35:27.816 A:middle
if you're going to
access the microphone.

696
00:35:29.076 --> 00:35:31.886 A:middle
You should at this time start
running because that's kind

697
00:35:31.886 --> 00:35:35.516 A:middle
of your final step of consent
saying, My engine is all hooked

698
00:35:35.516 --> 00:35:39.426 A:middle
up and ready to render,
start pulling on me.

699
00:35:39.986 --> 00:35:43.206 A:middle
You can, at this time,
start running even

700
00:35:43.206 --> 00:35:44.346 A:middle
if you are in the background.

701
00:35:44.346 --> 00:35:45.676 A:middle
This is the exception
to the rule

702
00:35:45.676 --> 00:35:46.826 A:middle
about running in the background.

703
00:35:47.466 --> 00:35:48.966 A:middle
When you are connected
to the host,

704
00:35:48.966 --> 00:35:52.066 A:middle
you can start running
in the background.

705
00:35:52.066 --> 00:35:53.306 A:middle
One further note, if you want

706
00:35:53.306 --> 00:35:55.476 A:middle
to draw an icon representing
the host

707
00:35:55.476 --> 00:35:56.856 A:middle
that you've become connected to,

708
00:35:57.186 --> 00:36:00.286 A:middle
there's a new API called
AudioOutputUnitGetHostIcon.

709
00:36:03.546 --> 00:36:07.036 A:middle
Pertaining further to the
IsInterAppConnected property,

710
00:36:07.036 --> 00:36:10.016 A:middle
you also want to watch
for the transition to zero

711
00:36:10.016 --> 00:36:13.166 A:middle
or false meaning that the host
has disconnected from you.

712
00:36:13.656 --> 00:36:17.466 A:middle
What you want to do at this
point is understand your output

713
00:36:17.466 --> 00:36:20.186 A:middle
unit has been uninitialized
and stopped for--

714
00:36:20.226 --> 00:36:21.296 A:middle
out from underneath you.

715
00:36:22.636 --> 00:36:25.646 A:middle
Now, if you were
accessing the microphone,

716
00:36:25.926 --> 00:36:28.206 A:middle
you should set your session
inactive at this time.

717
00:36:28.906 --> 00:36:31.476 A:middle
However, you might,
in some situations,

718
00:36:31.476 --> 00:36:35.336 A:middle
find yourself disconnected
while in the foreground.

719
00:36:35.336 --> 00:36:37.076 A:middle
Maybe the host application
crashed

720
00:36:37.076 --> 00:36:39.496 A:middle
or the system didn't have enough
memory to keep it running.

721
00:36:39.886 --> 00:36:42.666 A:middle
So, if that happens,
you probably do want

722
00:36:42.716 --> 00:36:45.196 A:middle
to start running and keep
your audio session active

723
00:36:45.196 --> 00:36:47.606 A:middle
or make it active
if it isn't already.

724
00:36:48.926 --> 00:36:50.746 A:middle
But again, you can only start--

725
00:36:50.836 --> 00:36:53.906 A:middle
you can only make your session
active and start running

726
00:36:53.906 --> 00:36:54.906 A:middle
when you're in the foreground.

727
00:36:55.506 --> 00:36:59.576 A:middle
So, just to reemphasize that.

728
00:37:00.586 --> 00:37:04.246 A:middle
Your node application can
start if you've been connected

729
00:37:04.246 --> 00:37:05.956 A:middle
to the host or you're
in the foreground

730
00:37:06.386 --> 00:37:08.326 A:middle
but you can keep running
in to the background

731
00:37:08.946 --> 00:37:11.366 A:middle
if you're connected, of
course, or if you are

732
00:37:11.366 --> 00:37:15.156 A:middle
in some other standalone
non inter-app scenario

733
00:37:15.316 --> 00:37:17.556 A:middle
where your app wants to keep
running in to the background.

734
00:37:21.506 --> 00:37:25.916 A:middle
Let's look again now at a few
different scenarios involving

735
00:37:25.946 --> 00:37:27.476 A:middle
how nodes render audio.

736
00:37:28.276 --> 00:37:30.486 A:middle
This is your normal
standalone mode

737
00:37:30.486 --> 00:37:31.686 A:middle
when the user has launched you.

738
00:37:32.346 --> 00:37:34.486 A:middle
You've got your engine
connected to the RemoteIO,

739
00:37:34.486 --> 00:37:37.036 A:middle
connected to the
audio I/O system.

740
00:37:37.446 --> 00:37:40.066 A:middle
If you're a generator
or instrument,

741
00:37:41.406 --> 00:37:44.406 A:middle
you may have your output
completely redirected

742
00:37:44.406 --> 00:37:45.706 A:middle
to the host.

743
00:37:47.156 --> 00:37:49.626 A:middle
But if you leave your
input bus enabled

744
00:37:49.766 --> 00:37:52.986 A:middle
but you advertise yourself
as a generator or instrument,

745
00:37:53.676 --> 00:37:56.566 A:middle
then you've continued
to receive input

746
00:37:56.566 --> 00:38:00.126 A:middle
from the microphone even while
your output has been redirected

747
00:38:00.126 --> 00:38:01.346 A:middle
to the host application.

748
00:38:02.186 --> 00:38:04.386 A:middle
Now, this doesn't
add any extra latency

749
00:38:05.406 --> 00:38:07.436 A:middle
because the system
is smart enough

750
00:38:07.436 --> 00:38:11.866 A:middle
to deliver your application, the
microphone input first and then

751
00:38:11.866 --> 00:38:15.936 A:middle
in that same I/O cycle, the
host application will pull

752
00:38:15.936 --> 00:38:16.646 A:middle
your output.

753
00:38:17.256 --> 00:38:21.466 A:middle
In the final node
rendering scenario -

754
00:38:21.866 --> 00:38:24.456 A:middle
is you have in effect
both your input

755
00:38:24.456 --> 00:38:26.796 A:middle
and output streams are
connected to the host rather

756
00:38:26.796 --> 00:38:29.386 A:middle
than the audio I/O system.

757
00:38:29.956 --> 00:38:34.026 A:middle
Node applications can also use

758
00:38:34.026 --> 00:38:36.506 A:middle
that PeerURL property
I described earlier

759
00:38:36.666 --> 00:38:40.496 A:middle
to show an icon as
Alec did in his demo.

760
00:38:41.286 --> 00:38:44.606 A:middle
He showed-- the Garageband
icon in the sampler app.

761
00:38:45.216 --> 00:38:48.446 A:middle
So, you can fetch that
icon from your remote--

762
00:38:48.446 --> 00:38:51.046 A:middle
your AURemoteIO instance
in this case.

763
00:38:51.046 --> 00:38:52.666 A:middle
You can-- I'm sorry.

764
00:38:52.666 --> 00:38:55.176 A:middle
You can fetch that URL
to accomplish the switch.

765
00:38:58.936 --> 00:39:00.926 A:middle
OK. Back on the host
side of things,

766
00:39:01.706 --> 00:39:04.496 A:middle
there are a few considerations
about stopping audio rendering.

767
00:39:05.476 --> 00:39:08.886 A:middle
The normal API calls for this
doing are AudioOutputUnitStop

768
00:39:08.886 --> 00:39:12.566 A:middle
or AUGraphStop and
what you want to do

769
00:39:12.566 --> 00:39:16.236 A:middle
at this point is promptly
uninitialize your AudioUnit

770
00:39:16.236 --> 00:39:17.276 A:middle
representing the node.

771
00:39:17.976 --> 00:39:20.696 A:middle
That releases the
resources that were allocated

772
00:39:20.756 --> 00:39:24.446 A:middle
when you initialized it and it
releases you from the promise

773
00:39:24.496 --> 00:39:25.836 A:middle
to keep rendering frequently.

774
00:39:27.076 --> 00:39:29.806 A:middle
You can turn around and
reinitialize when the user wants

775
00:39:29.806 --> 00:39:32.766 A:middle
to start communicating again
or if you're completely done

776
00:39:32.766 --> 00:39:33.996 A:middle
with that node AudioUnit,

777
00:39:33.996 --> 00:39:36.346 A:middle
you can call
AudioComponentInstanceDispose

778
00:39:37.066 --> 00:39:39.746 A:middle
and that's what you would do
the if the user, for example,

779
00:39:40.006 --> 00:39:43.176 A:middle
explicitly breaks the
connection or if you discover

780
00:39:43.176 --> 00:39:45.816 A:middle
that the node application
has become invalidated.

781
00:39:46.426 --> 00:39:50.326 A:middle
So, that's the process
of audio rendering.

782
00:39:51.056 --> 00:39:54.516 A:middle
Next, I'd like to look at how
we can communicate MIDI events

783
00:39:54.516 --> 00:39:57.256 A:middle
from host applications
to node applications.

784
00:39:57.726 --> 00:40:01.746 A:middle
Now, this of course, is
for remote instrument

785
00:40:01.816 --> 00:40:03.806 A:middle
and remote music effect nodes.

786
00:40:05.606 --> 00:40:07.986 A:middle
You would want to use this
if you have MIDI events

787
00:40:07.986 --> 00:40:11.486 A:middle
that are tightly coupled to your
audio that's being rendered.

788
00:40:12.126 --> 00:40:16.186 A:middle
It lets you sample-accurately
schedule MIDI note-ons,

789
00:40:16.186 --> 00:40:19.506 A:middle
control events, pitch-bends,
et cetera.

790
00:40:19.506 --> 00:40:23.436 A:middle
But this is not recommended as
a way of communicating clock

791
00:40:23.436 --> 00:40:24.876 A:middle
and time code information.

792
00:40:25.256 --> 00:40:28.516 A:middle
That's sort of a funny
way to communicate

793
00:40:28.516 --> 00:40:31.936 A:middle
that you're using seven
bit numbers to break

794
00:40:31.936 --> 00:40:33.596 A:middle
up timing information.

795
00:40:33.596 --> 00:40:35.456 A:middle
We actually have a
better way to do that.

796
00:40:35.916 --> 00:40:39.746 A:middle
I should also mention that this
does not replace the coreMIDI

797
00:40:39.746 --> 00:40:41.526 A:middle
framework which still has a role

798
00:40:41.926 --> 00:40:46.786 A:middle
when you're dealing USB MIDI
input and output devices or,

799
00:40:46.786 --> 00:40:48.326 A:middle
for example, the
MIDI network driver.

800
00:40:49.056 --> 00:40:51.046 A:middle
You might also be
dealing with applications

801
00:40:51.046 --> 00:40:53.126 A:middle
that don't support inter-app
audio and you still want

802
00:40:53.126 --> 00:40:57.236 A:middle
to communicate with them.

803
00:40:57.416 --> 00:41:00.276 A:middle
So, let's look at how a
host application can send

804
00:41:00.276 --> 00:41:01.246 A:middle
MIDI events.

805
00:41:01.526 --> 00:41:03.796 A:middle
You might do something
like this in this--

806
00:41:03.886 --> 00:41:06.526 A:middle
like the sampler demo
app, Alex showed.

807
00:41:06.686 --> 00:41:08.536 A:middle
It had an on-screen keyboard.

808
00:41:09.026 --> 00:41:11.966 A:middle
So, whenever the user touches
the key, you send a note-on.

809
00:41:11.966 --> 00:41:13.946 A:middle
When the key is released,
you send a note-off.

810
00:41:14.476 --> 00:41:17.816 A:middle
So, the APIs for
sending MIDI events are

811
00:41:17.816 --> 00:41:22.826 A:middle
in the header file MusicDevice.h
and there is a function

812
00:41:22.826 --> 00:41:24.966 A:middle
in there called
MusicDeviceMIDIEvent.

813
00:41:25.846 --> 00:41:28.466 A:middle
Here, you pass the
node AudioUnit,

814
00:41:28.956 --> 00:41:31.106 A:middle
the three byte MIDI--
MIDI message.

815
00:41:31.696 --> 00:41:34.826 A:middle
And here, offsetSampleFrames,
the final parameter,

816
00:41:35.386 --> 00:41:37.716 A:middle
that would be used for
sample-accurate scheduling

817
00:41:37.716 --> 00:41:42.226 A:middle
but since we're doing this
in kind of a UI context,

818
00:41:42.446 --> 00:41:45.956 A:middle
we don't really know how to have
that kind of sample accuracy.

819
00:41:46.256 --> 00:41:49.066 A:middle
I'll get into how
we do in a moment.

820
00:41:49.066 --> 00:41:51.966 A:middle
So, we just passed this sample
offset frames of zero that--

821
00:41:52.036 --> 00:41:54.176 A:middle
at that note-on will
appear at the beginning

822
00:41:54.176 --> 00:41:55.526 A:middle
of the next rendered buffer.

823
00:41:55.526 --> 00:41:59.446 A:middle
Now, if we do want to
do sample-accurate,

824
00:41:59.446 --> 00:42:03.006 A:middle
scheduling then we have to
schedule our MIDI events

825
00:42:03.006 --> 00:42:05.536 A:middle
on the same thread that
were rendering the audio,

826
00:42:05.976 --> 00:42:08.036 A:middle
because in that thread context,

827
00:42:08.136 --> 00:42:11.376 A:middle
we can say where the MIDI
events need to land relative

828
00:42:11.376 --> 00:42:12.806 A:middle
to the beginning of
that audio buffer.

829
00:42:13.346 --> 00:42:14.996 A:middle
For instance if that MIDI buffer

830
00:42:14.996 --> 00:42:19.416 A:middle
or audio buffer rather is 1,024
frames, we might do some math

831
00:42:19.416 --> 00:42:23.396 A:middle
and figure out, oh, that note-on
needs to land at 412 samples

832
00:42:23.396 --> 00:42:27.576 A:middle
in to that sample buffer and
we can specify that in our call

833
00:42:27.636 --> 00:42:29.966 A:middle
to MusicDeviceMIDIEvent.

834
00:42:30.416 --> 00:42:33.306 A:middle
Now, of course, we can call
MusicDeviceMIDIEvent any number

835
00:42:33.306 --> 00:42:36.716 A:middle
of times to schedule any number
of events for one render cycle.

836
00:42:36.716 --> 00:42:40.036 A:middle
I just put these next to each
other to emphasize that you have

837
00:42:40.036 --> 00:42:43.076 A:middle
to be in the rendering
thread context to be able

838
00:42:43.116 --> 00:42:45.466 A:middle
to schedule sample-accurately.

839
00:42:46.076 --> 00:42:48.616 A:middle
Now, for you're using
AUGraph and you want

840
00:42:48.616 --> 00:42:51.356 A:middle
to schedule sample-accurately,
it's similar

841
00:42:51.356 --> 00:42:54.566 A:middle
but a little different because
you're not calling AUGgraph--

842
00:42:54.566 --> 00:42:56.586 A:middle
I'm sorry, you're not
calling AudioUnitRender,

843
00:42:56.946 --> 00:42:58.776 A:middle
the graph is doing
that on your behalf.

844
00:42:59.846 --> 00:43:03.306 A:middle
So, the way to do this,
there's an AUGraph API

845
00:43:03.306 --> 00:43:06.296 A:middle
that lets you get called
back in the render context

846
00:43:06.296 --> 00:43:08.716 A:middle
and that's
AUGraphAddRenderNotify.

847
00:43:09.886 --> 00:43:12.926 A:middle
That gives you a callback
function that the graph calls

848
00:43:13.206 --> 00:43:15.876 A:middle
at the beginning of the render
cycle before actually pulling

849
00:43:15.876 --> 00:43:16.866 A:middle
audio from the node.

850
00:43:17.316 --> 00:43:20.456 A:middle
And that turns out to be
the precisely corrects time

851
00:43:20.866 --> 00:43:23.956 A:middle
to call MusicDeviceMIDIEvent
to schedule events

852
00:43:24.376 --> 00:43:25.666 A:middle
for that render cycle.

853
00:43:26.266 --> 00:43:29.926 A:middle
So, that's the process
of sending MIDIEvents,

854
00:43:30.586 --> 00:43:33.826 A:middle
let's look at how nodes
receive MIDI Events.

855
00:43:33.946 --> 00:43:35.756 A:middle
So, we have two basic
functions for sending

856
00:43:35.756 --> 00:43:37.416 A:middle
and then there's
MusicDeviceMIDIEvent

857
00:43:37.416 --> 00:43:38.836 A:middle
and MusicDeviceSysEx.

858
00:43:39.316 --> 00:43:42.846 A:middle
And we have two corresponding
callback functions for the use

859
00:43:42.846 --> 00:43:45.136 A:middle
of the node application,
the MIDIEventProc

860
00:43:45.136 --> 00:43:46.496 A:middle
and the MIDISysExProc.

861
00:43:48.826 --> 00:43:50.636 A:middle
So, in the node application,

862
00:43:50.636 --> 00:43:52.866 A:middle
here we have an example
of MIDIEventProc.

863
00:43:52.866 --> 00:43:55.456 A:middle
Well, it doesn't
do much but here is

864
00:43:55.456 --> 00:43:58.366 A:middle
where you receive each event
that's coming from the host

865
00:43:58.526 --> 00:44:02.376 A:middle
and typically, you would just
save it up in a local structure

866
00:44:02.976 --> 00:44:06.616 A:middle
and use it the next
time you render a buffer

867
00:44:08.276 --> 00:44:11.236 A:middle
because this function will
get called at the beginning

868
00:44:11.236 --> 00:44:14.046 A:middle
of each render cycle
with new events

869
00:44:14.046 --> 00:44:15.576 A:middle
that apply to that render cycle.

870
00:44:16.186 --> 00:44:18.586 A:middle
So, having created
that callback function,

871
00:44:18.586 --> 00:44:21.276 A:middle
we can populate a
structure of callbacks.

872
00:44:21.666 --> 00:44:23.906 A:middle
You can notice I left
the SysExProc null,

873
00:44:23.906 --> 00:44:25.876 A:middle
that just means I'm
not going to get called

874
00:44:25.936 --> 00:44:27.956 A:middle
if there is any SysEx.

875
00:44:28.036 --> 00:44:32.376 A:middle
We use AudioUnitSetProperty to
install those callbacks and now,

876
00:44:32.956 --> 00:44:34.486 A:middle
on the node application side,

877
00:44:34.486 --> 00:44:37.686 A:middle
I'm going to receive each
MIDIEvent as it arrives.

878
00:44:39.256 --> 00:44:43.256 A:middle
So, that's how hosts
can sent MIDI to nodes.

879
00:44:43.756 --> 00:44:47.016 A:middle
Let's look now at how host can
communicate their transport

880
00:44:47.016 --> 00:44:48.656 A:middle
and timeline information
to nodes.

881
00:44:49.226 --> 00:44:53.476 A:middle
So, the important thing
about this model is

882
00:44:53.476 --> 00:44:55.546 A:middle
that the host is
always the master here.

883
00:44:56.256 --> 00:44:58.846 A:middle
The nodes can just find
out where the host is

884
00:44:58.846 --> 00:45:00.016 A:middle
and synchronize to that.

885
00:45:00.266 --> 00:45:04.976 A:middle
We'll look at how the host can
communicate its musical position

886
00:45:05.866 --> 00:45:08.126 A:middle
as well as the state
of its transport.

887
00:45:08.126 --> 00:45:12.366 A:middle
And all of this is highly
precise and it's called

888
00:45:12.366 --> 00:45:15.246 A:middle
and pertains to the
render context.

889
00:45:15.596 --> 00:45:21.116 A:middle
So here too, we have a structure
full of callback functions,

890
00:45:21.226 --> 00:45:22.496 A:middle
we'll look at each of these.

891
00:45:23.466 --> 00:45:26.496 A:middle
So, this is probably
the most common one

892
00:45:26.496 --> 00:45:27.816 A:middle
that a host will implement,

893
00:45:28.206 --> 00:45:30.346 A:middle
this is called the
BeatAndTempo callback.

894
00:45:31.166 --> 00:45:33.666 A:middle
Here, the host can
say for the beginning

895
00:45:33.666 --> 00:45:37.136 A:middle
of the current audio buffer,
Where am I in the track

896
00:45:37.136 --> 00:45:40.826 A:middle
and that could be
in between beats.

897
00:45:40.826 --> 00:45:44.756 A:middle
The host can also communicate
what the current tempo is.

898
00:45:44.866 --> 00:45:48.116 A:middle
And so with these two pieces
of information, even--

899
00:45:48.116 --> 00:45:50.126 A:middle
even only these two
pieces information,

900
00:45:50.126 --> 00:45:52.776 A:middle
the node can do beat
synchronized effects

901
00:45:52.776 --> 00:45:54.546 A:middle
from the host for instance.

902
00:45:55.116 --> 00:46:01.016 A:middle
There's also some more detailed
musical location information

903
00:46:01.016 --> 00:46:03.816 A:middle
supplied by the host such as
the current time signature.

904
00:46:03.896 --> 00:46:08.556 A:middle
And finally, the host
can communicate some bits

905
00:46:08.556 --> 00:46:11.126 A:middle
of transport state, most
notably whether it's playing

906
00:46:11.126 --> 00:46:11.806 A:middle
or recording.

907
00:46:11.806 --> 00:46:14.546 A:middle
There's also a facility
for the host

908
00:46:14.546 --> 00:46:17.576 A:middle
to express whether it's
cycling or looping.

909
00:46:20.636 --> 00:46:23.546 A:middle
So here too, we're installing
a set of callback from--

910
00:46:23.606 --> 00:46:26.876 A:middle
callback functions
on an audio unit.

911
00:46:26.876 --> 00:46:29.576 A:middle
The host populates the host
callback info structure,

912
00:46:29.926 --> 00:46:32.766 A:middle
installs the callback
functions that it implements

913
00:46:32.956 --> 00:46:34.886 A:middle
and calls AudioUnitSetProperty.

914
00:46:35.416 --> 00:46:39.576 A:middle
So, once the host does this, the
system will call those callbacks

915
00:46:39.576 --> 00:46:42.466 A:middle
at the beginning of each
render cycle and communicate

916
00:46:42.466 --> 00:46:45.436 A:middle
that over-- that information
over to the node process

917
00:46:46.456 --> 00:46:50.256 A:middle
where the node application
will have access to them.

918
00:46:50.586 --> 00:46:54.906 A:middle
And the way the node
application gets that access is

919
00:46:54.906 --> 00:46:56.936 A:middle
by fetching the host
callback property.

920
00:46:57.926 --> 00:47:01.076 A:middle
It will receive that structure
full of function pointers.

921
00:47:01.076 --> 00:47:02.656 A:middle
They won't actually
point to functions

922
00:47:02.656 --> 00:47:05.326 A:middle
in the host process, of course.

923
00:47:05.526 --> 00:47:08.496 A:middle
We can't make a cross process
call there, but the information,

924
00:47:08.496 --> 00:47:11.506 A:middle
as I just said, has been
communicated over to the node.

925
00:47:11.506 --> 00:47:16.006 A:middle
And it can access them there
within its own process.

926
00:47:17.016 --> 00:47:21.016 A:middle
There are some considerations
of thread safety here.

927
00:47:21.256 --> 00:47:25.856 A:middle
Most people importantly, since
this information is accurate

928
00:47:25.856 --> 00:47:28.736 A:middle
as of the beginning of the
render cycle, if you call it

929
00:47:28.736 --> 00:47:33.446 A:middle
in some other context, you
might get inconsistent results.

930
00:47:33.826 --> 00:47:38.856 A:middle
It's easiest if you fetch this
information on the render thread

931
00:47:39.236 --> 00:47:41.466 A:middle
but of course, there are
some cases where you want

932
00:47:41.466 --> 00:47:43.936 A:middle
to observe a transport
state for instance.

933
00:47:44.716 --> 00:47:49.986 A:middle
So, we give you a better
way to receive notifications

934
00:47:49.986 --> 00:47:54.146 A:middle
of transport state changes on
a non-render thread context.

935
00:47:54.576 --> 00:47:56.236 A:middle
You can install this
property listener

936
00:47:56.236 --> 00:47:59.176 A:middle
for the HostTransportState
and get a callback

937
00:47:59.526 --> 00:48:00.796 A:middle
on a non-render thread.

938
00:48:01.456 --> 00:48:05.176 A:middle
Okay, so that's the
process of transport

939
00:48:05.176 --> 00:48:06.386 A:middle
and timeline information.

940
00:48:06.386 --> 00:48:09.136 A:middle
Finally, I'd like to look
at the whole mechanism

941
00:48:09.136 --> 00:48:12.366 A:middle
by which node applications
can send remote control events

942
00:48:12.606 --> 00:48:13.856 A:middle
to host applications.

943
00:48:14.016 --> 00:48:16.966 A:middle
To accomplish that, we
have something called

944
00:48:17.206 --> 00:48:19.476 A:middle
AudioUnitRemoteControlEvents.

945
00:48:19.646 --> 00:48:21.916 A:middle
Now, there's something
called RemoteControlEvents

946
00:48:21.916 --> 00:48:23.116 A:middle
in UIKit as well.

947
00:48:23.116 --> 00:48:26.386 A:middle
Those are kind of in
a different world.

948
00:48:27.036 --> 00:48:30.286 A:middle
These are more specific to the
needs of audio applications.

949
00:48:30.776 --> 00:48:33.896 A:middle
So with these events, the
node can control the host

950
00:48:33.896 --> 00:48:35.366 A:middle
application's transport.

951
00:48:35.896 --> 00:48:38.566 A:middle
And for now, we have these
three events to find.

952
00:48:38.716 --> 00:48:42.186 A:middle
You can toggle-- you being a
node application-can toggle the

953
00:48:42.806 --> 00:48:49.116 A:middle
host's play or pause state, its
recording state and the node,

954
00:48:49.246 --> 00:48:51.066 A:middle
through an event, can
send the host back

955
00:48:51.066 --> 00:48:54.096 A:middle
to the beginning of
the song or track.

956
00:48:54.636 --> 00:48:56.666 A:middle
We do have some sample
applications

957
00:48:56.666 --> 00:49:00.116 A:middle
where our node applications
have some standard looking

958
00:49:00.116 --> 00:49:01.166 A:middle
transport controls.

959
00:49:01.166 --> 00:49:03.486 A:middle
And we'd like to encourage you
to check those out and use them

960
00:49:03.486 --> 00:49:06.836 A:middle
in your application so that
we can have a consistent look

961
00:49:06.836 --> 00:49:08.146 A:middle
and feel for these controls.

962
00:49:09.796 --> 00:49:14.436 A:middle
So, looking at how node
applications can send

963
00:49:15.046 --> 00:49:17.356 A:middle
RemoteControlEvents,
first, we want to find

964
00:49:17.356 --> 00:49:19.736 A:middle
out whether the host actually
is listening and is going

965
00:49:19.736 --> 00:49:21.416 A:middle
to support them because
if it doesn't,

966
00:49:21.416 --> 00:49:22.326 A:middle
maybe we don't even want

967
00:49:22.326 --> 00:49:24.486 A:middle
to bother drawing the
transport controls at all.

968
00:49:24.996 --> 00:49:26.836 A:middle
So to do that, we can
fetch this property

969
00:49:26.836 --> 00:49:28.946 A:middle
HostReceivesRemoteControlEvents.

970
00:49:29.826 --> 00:49:32.186 A:middle
And to actually send
the RemoteControlEvent,

971
00:49:32.756 --> 00:49:35.916 A:middle
the node calls
AudioUnitSetProperty using the

972
00:49:35.916 --> 00:49:37.996 A:middle
remote control to
event or I'm sorry,

973
00:49:37.996 --> 00:49:39.476 A:middle
remote control to host event.

974
00:49:39.716 --> 00:49:43.066 A:middle
And the value of that
property is the actual control

975
00:49:43.066 --> 00:49:45.766 A:middle
to be sent, toggle, or
record on this example.

976
00:49:46.806 --> 00:49:49.386 A:middle
So, there's a node sending
a RemoteControlEvent.

977
00:49:50.286 --> 00:49:55.146 A:middle
Here is a host receiving
one or rather preparing

978
00:49:55.146 --> 00:49:56.266 A:middle
to receive them, I should say.

979
00:49:57.006 --> 00:50:00.046 A:middle
So, to do that, the host creates
a block called the listenerBlock

980
00:50:01.766 --> 00:50:06.016 A:middle
and in that block, the host
simply takes the incoming

981
00:50:06.016 --> 00:50:09.246 A:middle
AudioUnitRemoteControlEvent
and passes it to one

982
00:50:09.246 --> 00:50:11.886 A:middle
of its own methods called
handleRemoteControlEvent.

983
00:50:12.626 --> 00:50:16.426 A:middle
Now, that block is in
turn a property value

984
00:50:16.426 --> 00:50:18.576 A:middle
for the
RemoteControlEventListener

985
00:50:18.576 --> 00:50:22.266 A:middle
property so the host only
has to set that property

986
00:50:22.596 --> 00:50:27.836 A:middle
on the node AudioUnit and that
accomplishes the installation

987
00:50:27.866 --> 00:50:29.856 A:middle
of the listener for
RemoteControlEvents.

988
00:50:30.306 --> 00:50:33.656 A:middle
Next, I'd like to bring up
my colleague Harry Tormey

989
00:50:33.656 --> 00:50:35.996 A:middle
to show you about some
of these other aspects

990
00:50:35.996 --> 00:50:38.096 A:middle
of the inter-app
audio API in action.

991
00:50:38.886 --> 00:50:42.136 A:middle
&gt;&gt; Thanks Doug.

992
00:50:42.486 --> 00:50:46.586 A:middle
Hey everybody, my name is Harry
Tormey and I work with Doug

993
00:50:46.586 --> 00:50:47.946 A:middle
in the Core Audio
Group at Apple.

994
00:50:48.626 --> 00:50:51.626 A:middle
And today, I'm going to be
giving you a demonstration

995
00:50:51.626 --> 00:50:53.526 A:middle
of some of the sample
applications we're going

996
00:50:53.526 --> 00:50:55.136 A:middle
to be releasing on
the developer portal

997
00:50:55.206 --> 00:50:57.616 A:middle
to illustrate how
inter-app audio works.

998
00:50:59.066 --> 00:51:00.936 A:middle
The first demo I'm going
to be giving you is

999
00:51:00.936 --> 00:51:05.616 A:middle
of a host application connecting
to a sampler node application

1000
00:51:05.896 --> 00:51:07.686 A:middle
and sending it some MIDI events.

1001
00:51:08.506 --> 00:51:11.616 A:middle
So what you see in the screen
up there is a host application

1002
00:51:11.616 --> 00:51:13.276 A:middle
and I'm going to bring up a list

1003
00:51:13.276 --> 00:51:16.996 A:middle
of all the remote instrument
node applications installed

1004
00:51:16.996 --> 00:51:18.186 A:middle
on this device and
I'm going to do

1005
00:51:18.186 --> 00:51:19.776 A:middle
that by touching the
add instrument button.

1006
00:51:21.026 --> 00:51:24.016 A:middle
So, none of these applications
are currently running.

1007
00:51:24.476 --> 00:51:25.886 A:middle
They have just published
themselves

1008
00:51:25.886 --> 00:51:27.506 A:middle
with their audio
component descriptions.

1009
00:51:27.806 --> 00:51:30.516 A:middle
When I select one of these
applications from the list,

1010
00:51:30.746 --> 00:51:33.596 A:middle
it will launch into the
background and connect

1011
00:51:33.596 --> 00:51:35.076 A:middle
to the host application.

1012
00:51:35.456 --> 00:51:37.636 A:middle
So I'm going to do that, I'm
going to select the sampler.

1013
00:51:38.756 --> 00:51:41.786 A:middle
OK. So, you can see
the sampler's icon

1014
00:51:41.786 --> 00:51:44.056 A:middle
up there underneath
the instrument label.

1015
00:51:44.276 --> 00:51:46.246 A:middle
That means it's connected
to the host application.

1016
00:51:46.576 --> 00:51:49.106 A:middle
So, I'm going to bring
up a keyboard in the host

1017
00:51:49.106 --> 00:51:52.166 A:middle
by touching the show
keyboard button and I'm going

1018
00:51:52.166 --> 00:51:55.466 A:middle
to send some MIDI
events from the host

1019
00:51:55.466 --> 00:52:00.556 A:middle
to the sampler by
playing the keys.

1020
00:52:00.686 --> 00:52:01.436 A:middle
[Music] Totally awesome.

1021
00:52:02.336 --> 00:52:06.866 A:middle
OK. So, what if I want
to change the sample bank

1022
00:52:06.866 --> 00:52:08.056 A:middle
that the sampler is using?

1023
00:52:08.386 --> 00:52:10.616 A:middle
Well, I'm going to have to do
to the sampler and do that.

1024
00:52:11.106 --> 00:52:13.216 A:middle
I'm going to do that by
touching the sampler's icon.

1025
00:52:14.016 --> 00:52:16.816 A:middle
We're now in a separate
application and I'm going

1026
00:52:16.816 --> 00:52:19.826 A:middle
to select a different
sample bank to use so how

1027
00:52:19.826 --> 00:52:21.596 A:middle
about something nice
like a harpsichord?

1028
00:52:22.026 --> 00:52:24.256 A:middle
Let me just do that there.

1029
00:52:24.256 --> 00:52:26.026 A:middle
OK. So now, we're
in harpsichord,

1030
00:52:26.026 --> 00:52:28.546 A:middle
I'm going to touch the
host icon there and go back

1031
00:52:28.546 --> 00:52:29.666 A:middle
to the host application.

1032
00:52:30.356 --> 00:52:36.736 A:middle
Touch the show keyboard
again and listen for it.

1033
00:52:36.736 --> 00:52:36.803 A:middle
[ Music ]

1034
00:52:36.803 --> 00:52:38.576 A:middle
That's a harpsichord.

1035
00:52:39.746 --> 00:52:42.186 A:middle
OK. So, the next thing that
I'm going to show you is how

1036
00:52:42.186 --> 00:52:45.716 A:middle
to use the callbacks that the
host application has published

1037
00:52:45.996 --> 00:52:49.676 A:middle
to get the time code of the
host application when it records

1038
00:52:49.676 --> 00:52:50.616 A:middle
and plays back things.

1039
00:52:50.896 --> 00:52:53.446 A:middle
So one again, I'm going to go
the sampler by touching its icon

1040
00:52:53.446 --> 00:52:57.286 A:middle
and I'm going to touch the
record button and I'm going

1041
00:52:57.286 --> 00:52:59.346 A:middle
to record some audio in the host

1042
00:52:59.346 --> 00:53:01.816 A:middle
so I'm sending a remote
message to the host.

1043
00:53:02.876 --> 00:53:06.836 A:middle
[Music] I'm going
to stop recoding

1044
00:53:06.836 --> 00:53:07.966 A:middle
by touching record button again.

1045
00:53:08.216 --> 00:53:09.366 A:middle
Now, what I want
you to pay attention

1046
00:53:09.366 --> 00:53:12.196 A:middle
to is the blue text
over the play button.

1047
00:53:12.806 --> 00:53:15.286 A:middle
This text is going to be
updated with the callbacks

1048
00:53:15.286 --> 00:53:17.396 A:middle
that the host application
has published and were going

1049
00:53:17.396 --> 00:53:20.686 A:middle
to use this to display a
time code indicating how far

1050
00:53:20.686 --> 00:53:21.786 A:middle
into the recording we are.

1051
00:53:21.786 --> 00:53:28.126 A:middle
So, I'm going to touch the play
button and watch that text.

1052
00:53:28.126 --> 00:53:33.766 A:middle
[Music] So, if I do
that again and I go

1053
00:53:33.766 --> 00:53:36.596 A:middle
to the host application, you'll
see the time code is consistent

1054
00:53:36.596 --> 00:53:38.856 A:middle
across both applications
so let me do that.

1055
00:53:38.856 --> 00:53:41.666 A:middle
Let me press play again and go
to-- back to host application.

1056
00:53:42.116 --> 00:53:50.986 A:middle
[Music] Okay, so
for my grand finale,

1057
00:53:51.326 --> 00:53:54.756 A:middle
I'm going to add an effect
and that effect is going

1058
00:53:54.756 --> 00:53:56.426 A:middle
to be the delay effect
that you saw.

1059
00:53:56.466 --> 00:53:59.046 A:middle
So once again, I touched
the add effect button.

1060
00:53:59.316 --> 00:54:00.786 A:middle
It shows you all of the effects

1061
00:54:00.786 --> 00:54:02.746 A:middle
that are installed
on this device.

1062
00:54:02.746 --> 00:54:04.876 A:middle
I'm going to select the delay
one, it's going to launch it

1063
00:54:04.876 --> 00:54:07.446 A:middle
and connect to the host.

1064
00:54:07.446 --> 00:54:11.486 A:middle
OK. So in the host, if I touched
the show keyboard button again

1065
00:54:11.486 --> 00:54:13.636 A:middle
and play a note, it's
going to be delayed.

1066
00:54:18.236 --> 00:54:18.836 A:middle
[Music] How about that?

1067
00:54:18.966 --> 00:54:20.776 A:middle
Much cooler than
remote controlled cars.

1068
00:54:21.256 --> 00:54:24.546 A:middle
Okay everyone, that's
me, these demos are all

1069
00:54:24.546 --> 00:54:28.296 A:middle
up on the developer portal and
I'm done with my demo so back

1070
00:54:28.296 --> 00:54:29.746 A:middle
over to you Doug and
thank you very much.

1071
00:54:30.246 --> 00:54:32.806 A:middle
[Applause]

1072
00:54:33.306 --> 00:54:33.896 A:middle
&gt;&gt; Thank you Harry.

1073
00:54:33.896 --> 00:54:37.556 A:middle
Hey, I found the right button.

1074
00:54:38.006 --> 00:54:44.726 A:middle
So, back to some more
mundane matters here.

1075
00:54:44.826 --> 00:54:47.516 A:middle
Dealing with audio session
interruptions, both host

1076
00:54:47.516 --> 00:54:49.346 A:middle
and node applications
need to deal

1077
00:54:49.346 --> 00:54:50.706 A:middle
with audio session
interruptions.

1078
00:54:51.296 --> 00:54:53.996 A:middle
Here, the usual rules
apply namely

1079
00:54:53.996 --> 00:54:56.696 A:middle
that your AURemoteIO gets
stopped underneath you.

1080
00:54:56.696 --> 00:54:59.296 A:middle
But furthermore, in
a host application,

1081
00:54:59.296 --> 00:55:02.096 A:middle
the system will uninitialize
any node AudioUnits

1082
00:55:02.096 --> 00:55:02.956 A:middle
that you have open.

1083
00:55:03.366 --> 00:55:06.126 A:middle
This will reclaim the
resources I've been talking

1084
00:55:06.126 --> 00:55:10.506 A:middle
about that you acquire when you
initialize the node AudioUnit.

1085
00:55:12.076 --> 00:55:14.376 A:middle
One other bit of
housekeeping here,

1086
00:55:14.836 --> 00:55:16.866 A:middle
you can make your
application more robust

1087
00:55:16.866 --> 00:55:19.886 A:middle
if you handle a media
services reset correctly.

1088
00:55:19.946 --> 00:55:25.506 A:middle
It's a little bit hard to test
this sometimes-- oops, but--

1089
00:55:25.506 --> 00:55:28.946 A:middle
let me find my way back.

1090
00:55:29.796 --> 00:55:33.146 A:middle
But if you implement this,

1091
00:55:33.146 --> 00:55:37.476 A:middle
your application will
survive calamities.

1092
00:55:38.276 --> 00:55:40.506 A:middle
So, when this happens, you can--

1093
00:55:40.506 --> 00:55:42.256 A:middle
you will find out that all

1094
00:55:42.256 --> 00:55:44.646 A:middle
of your inter-app audio
connections have been broken,

1095
00:55:44.646 --> 00:55:46.826 A:middle
the component instances
have been invalidated.

1096
00:55:47.236 --> 00:55:50.086 A:middle
So, in a host audio--
host application,

1097
00:55:50.086 --> 00:55:53.376 A:middle
you should dispose your node
AudioUnit and your AURemoteIO.

1098
00:55:53.906 --> 00:55:55.486 A:middle
And in a node application,

1099
00:55:55.636 --> 00:55:57.836 A:middle
you should also dispose
your AURemoteIO.

1100
00:55:58.346 --> 00:56:00.016 A:middle
So in general, it's simplest

1101
00:56:00.016 --> 00:56:03.026 A:middle
to dispose your entire audio
engine including those Apple

1102
00:56:03.026 --> 00:56:03.936 A:middle
Audio objects.

1103
00:56:04.716 --> 00:56:07.166 A:middle
And then, start over
from scratch

1104
00:56:07.166 --> 00:56:09.246 A:middle
as if your app has
just been launched

1105
00:56:09.476 --> 00:56:10.786 A:middle
and that's the simplest way

1106
00:56:10.786 --> 00:56:14.316 A:middle
to robustly handle the
media services being reset.

1107
00:56:16.856 --> 00:56:19.976 A:middle
Some questions that have come
up in showing this feature

1108
00:56:19.976 --> 00:56:21.626 A:middle
to people, in talking with them,

1109
00:56:21.986 --> 00:56:24.506 A:middle
can you have multiple
host applications?

1110
00:56:24.906 --> 00:56:26.456 A:middle
Yes, if they are all mixable.

1111
00:56:26.996 --> 00:56:29.056 A:middle
If one is unmixable, of course,

1112
00:56:29.056 --> 00:56:32.126 A:middle
it will interrupt everything
else as it takes control.

1113
00:56:32.896 --> 00:56:36.336 A:middle
Also, if you were to have
multiple host that are mixable

1114
00:56:36.336 --> 00:56:41.686 A:middle
and one node application,
only one host can connect

1115
00:56:41.776 --> 00:56:42.936 A:middle
to that node at a time.

1116
00:56:43.686 --> 00:56:45.536 A:middle
Can you have multiple
node applications?

1117
00:56:45.536 --> 00:56:48.646 A:middle
Yes, Harry just showed us that
that's more than possible.

1118
00:56:49.246 --> 00:56:53.016 A:middle
A couple of debugging
tips here you may find

1119
00:56:53.106 --> 00:56:55.076 A:middle
when creating a node application

1120
00:56:55.076 --> 00:56:57.356 A:middle
that you're having
trouble getting it to show

1121
00:56:57.356 --> 00:56:59.236 A:middle
up in host applications.

1122
00:57:00.346 --> 00:57:03.116 A:middle
If you see that happening, you
should watch the system log.

1123
00:57:03.246 --> 00:57:05.896 A:middle
We try to leave some
clues for you there

1124
00:57:06.316 --> 00:57:07.696 A:middle
in the form of error messages.

1125
00:57:08.016 --> 00:57:10.376 A:middle
If you see a problem with
your Info.plist entry

1126
00:57:10.376 --> 00:57:13.076 A:middle
which is a little bit
easy to do unfortunately

1127
00:57:13.076 --> 00:57:15.356 A:middle
but if you do see a problem
there, we'll tell you that

1128
00:57:15.846 --> 00:57:18.786 A:middle
and I would recommend going
and comparing your Info.plist

1129
00:57:19.036 --> 00:57:21.656 A:middle
with the one-- in one of
our example applications.

1130
00:57:21.896 --> 00:57:26.556 A:middle
I should also mention here
the infamous error of 12,985

1131
00:57:26.586 --> 00:57:29.666 A:middle
which many people stub
their toes on in a lot

1132
00:57:29.666 --> 00:57:30.786 A:middle
of different contexts.

1133
00:57:31.256 --> 00:57:34.786 A:middle
I can tell you that what it
means is operation denied.

1134
00:57:35.436 --> 00:57:40.256 A:middle
And in the context of inter-app
audio, you're likely to hit it

1135
00:57:40.416 --> 00:57:41.986 A:middle
if you start playing
from the background.

1136
00:57:42.886 --> 00:57:47.136 A:middle
We do hope to in an upcoming
release give that a proper name

1137
00:57:47.136 --> 00:57:50.036 A:middle
and maybe another
value but in any case,

1138
00:57:50.036 --> 00:57:51.546 A:middle
if you do see it,
that's what it means.

1139
00:57:52.636 --> 00:57:55.866 A:middle
So we've looked at how node
applications register themselves

1140
00:57:55.866 --> 00:57:58.156 A:middle
with the system,
hosts discover them.

1141
00:57:58.846 --> 00:58:01.856 A:middle
Hosts create connections
to node applications.

1142
00:58:03.166 --> 00:58:06.946 A:middle
Once that connection is up, host
and node apps can stream audio

1143
00:58:06.946 --> 00:58:08.206 A:middle
to and from each other.

1144
00:58:08.526 --> 00:58:11.066 A:middle
Host apps can send MIDI
to node applications.

1145
00:58:11.736 --> 00:58:13.646 A:middle
Hosts can communicate
their transport

1146
00:58:13.646 --> 00:58:14.916 A:middle
and timeline information.

1147
00:58:15.416 --> 00:58:19.176 A:middle
And finally, we have seen how
nodes can remotely control hosts

1148
00:58:20.396 --> 00:58:23.246 A:middle
so I think if you
have an existing music

1149
00:58:23.246 --> 00:58:26.086 A:middle
or audio application,
it's not that much work

1150
00:58:26.086 --> 00:58:27.466 A:middle
to convert it to a node.

1151
00:58:27.996 --> 00:58:30.206 A:middle
It's mostly adding a
little bit of code to deal

1152
00:58:30.206 --> 00:58:32.966 A:middle
with the transitions to and
from the connected state

1153
00:58:33.016 --> 00:58:34.596 A:middle
and you can look how that works

1154
00:58:34.966 --> 00:58:37.286 A:middle
in the example apps
we have posted.

1155
00:58:37.896 --> 00:58:40.156 A:middle
Creating a host application
is a bit more work

1156
00:58:40.156 --> 00:58:43.016 A:middle
but you're using existing
API for audio units

1157
00:58:43.016 --> 00:58:45.726 A:middle
and there's a lot of history
there as well as powerful--

1158
00:58:46.046 --> 00:58:47.706 A:middle
there's a lot of
power and flexibility.

1159
00:58:49.186 --> 00:58:50.276 A:middle
We also like you to--

1160
00:58:50.726 --> 00:58:53.786 A:middle
we encourage you to look
at our sample applications.

1161
00:58:54.336 --> 00:58:56.646 A:middle
They'll help you with a lot
of the little ins and outs

1162
00:58:56.996 --> 00:58:58.156 A:middle
and we're really looking forward

1163
00:58:58.156 --> 00:59:01.296 A:middle
to the great music apps
you're going to make.

1164
00:59:01.846 --> 00:59:05.416 A:middle
On to some housekeeping matters
here, if you wish to talk

1165
00:59:05.416 --> 00:59:07.656 A:middle
to an Apple Evangelist,
there's John Geleynse.

1166
00:59:07.956 --> 00:59:11.056 A:middle
Here are some links
to some documentation

1167
00:59:11.056 --> 00:59:12.546 A:middle
and our developer forums.

1168
00:59:13.176 --> 00:59:15.346 A:middle
This is the only Core
Audio Session this year

1169
00:59:15.806 --> 00:59:18.756 A:middle
but here are some other media
sessions later this week

1170
00:59:18.756 --> 00:59:19.926 A:middle
that you might be interested in.

1171
00:59:20.766 --> 00:59:21.806 A:middle
Thank you very much.

1172
00:59:22.306 --> 00:59:29.690 A:middle
[ Silence ]

